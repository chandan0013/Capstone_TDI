{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing the hawks dataset\n",
    "# Features imported are number of followers, posting date of the tweet, retweet count\n",
    "\n",
    "import json\n",
    "import datetime, time\n",
    "\n",
    "\n",
    "f = open('C:\\\\Users\\\\Chandan\\\\Desktop\\\\DATA\\\\tweets_#gohawks.txt',encoding=\"utf8\")\n",
    "\n",
    "line = f.readline()\n",
    "\n",
    "\n",
    "tweet_hawks_followers = []\n",
    "tweet_hawks_pdate = []\n",
    "tweet_hawks_rcount = []\n",
    "tweet_hawks_imp = []\n",
    "tweet_hawks_rank = []\n",
    "tweet_hawks_cite = []\n",
    "user_id_hawks = []\n",
    "\n",
    "while len(line)!=0:\n",
    "    tweet = json.loads(line)\n",
    "    tweet_hawks_followers.append(tweet['tweet']['user']['followers_count'])\n",
    "    tweet_hawks_pdate.append(tweet['firstpost_date'])\n",
    "    tweet_hawks_rcount.append(tweet['metrics']['citations']['total'])\n",
    "    tweet_hawks_imp.append(tweet['metrics']['impressions'])\n",
    "    tweet_hawks_rank.append(tweet['metrics']['ranking_score'])\n",
    "    tweet_hawks_cite.append(tweet['tweet']['retweet_count'])\n",
    "    user_id_hawks.append(tweet['tweet']['user']['id'])\n",
    "    line = f.readline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193.54482518973285\n",
      "1709.424748600456\n",
      "2.014611770208785\n"
     ]
    }
   ],
   "source": [
    "# Hawks stats\n",
    "\n",
    "import numpy as np\n",
    "h,ind_hawks = np.unique(user_id_hawks,return_index=True)\n",
    "\n",
    "numtweets_hawks = len(tweet_hawks_followers)\n",
    "\n",
    "start_time_hawks = tweet_hawks_pdate[0]\n",
    "end_time_hawks = tweet_hawks_pdate[numtweets_hawks - 1]\n",
    "duration_hawks = (end_time_hawks - start_time_hawks)/3600\n",
    "\n",
    "num_followers_hawks = 0\n",
    "num_retweets_hawks = 0\n",
    "\n",
    "for i in range(0,numtweets_hawks - 1):\n",
    "        \n",
    "    num_retweets_hawks = num_retweets_hawks + tweet_hawks_rcount[i]\n",
    "    \n",
    "\n",
    "tweet_hawks_unique =  [tweet_hawks_followers[i] for i in ind_hawks]\n",
    "\n",
    "avg_num_tweets_hawks = numtweets_hawks / duration_hawks\n",
    "avg_num_followers_hawks = sum(tweet_hawks_unique) / len(h)\n",
    "avg_num_retweets_hawks = num_retweets_hawks / numtweets_hawks\n",
    "\n",
    "print(avg_num_tweets_hawks)\n",
    "print(avg_num_followers_hawks)\n",
    "print(avg_num_retweets_hawks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the gopatriots dataset\n",
    "# Features imported are number of followers, posting date of the tweet, retweet count\n",
    "\n",
    "import json\n",
    "import datetime, time\n",
    "\n",
    "\n",
    "f = open('C:\\\\Users\\\\Chandan\\\\Desktop\\\\DATA\\\\tweets_#gopatriots.txt',encoding=\"utf8\")\n",
    "\n",
    "line = f.readline()\n",
    "\n",
    "\n",
    "tweet_gp_followers = []\n",
    "tweet_gp_pdate = []\n",
    "tweet_gp_rcount = []\n",
    "tweet_gp_imp = []\n",
    "tweet_gp_rank = []\n",
    "tweet_gp_cite = []\n",
    "user_id_gp = []\n",
    "\n",
    "while len(line)!=0:\n",
    "    tweet = json.loads(line)\n",
    "    tweet_gp_followers.append(tweet['tweet']['user']['followers_count'])\n",
    "    tweet_gp_pdate.append(tweet['firstpost_date'])\n",
    "    tweet_gp_rcount.append(tweet['metrics']['citations']['total'])\n",
    "    tweet_gp_imp.append(tweet['metrics']['impressions'])\n",
    "    tweet_gp_rank.append(tweet['metrics']['ranking_score'])\n",
    "    tweet_gp_cite.append(tweet['tweet']['retweet_count'])\n",
    "    user_id_gp.append(tweet['tweet']['user']['id'])\n",
    "    line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.38470386915044\n",
      "1558.154512635379\n",
      "1.4000457456541628\n"
     ]
    }
   ],
   "source": [
    "# GoPatriots stats\n",
    "\n",
    "numtweets_gp = len(tweet_gp_followers)\n",
    "import numpy as np\n",
    "gp,ind_gp = np.unique(user_id_gp,return_index=True)\n",
    "\n",
    "\n",
    "\n",
    "start_time_gp = tweet_gp_pdate[0]\n",
    "end_time_gp = tweet_gp_pdate[numtweets_gp - 1]\n",
    "duration_gp = (end_time_gp - start_time_gp)/3600\n",
    "\n",
    "num_followers_gp = 0\n",
    "num_retweets_gp = 0\n",
    "\n",
    "for i in range(0,numtweets_gp - 1):\n",
    "    \n",
    "    num_retweets_gp = num_retweets_gp + tweet_gp_rcount[i]\n",
    "\n",
    "tweet_gp_unique =  [tweet_gp_followers[i] for i in ind_gp]\n",
    "avg_num_tweets_gp = numtweets_gp / duration_gp\n",
    "avg_num_followers_gp = sum(tweet_gp_unique) / len(gp) \n",
    "avg_num_retweets_gp = num_retweets_gp / numtweets_gp\n",
    "\n",
    "print(avg_num_tweets_gp)\n",
    "print(avg_num_followers_gp)\n",
    "print(avg_num_retweets_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the patriots dataset\n",
    "# Features imported are number of followers, posting date of the tweet, retweet count\n",
    "\n",
    "import json\n",
    "import datetime, time\n",
    "\n",
    "\n",
    "f = open('C:\\\\Users\\\\Chandan\\\\Desktop\\\\DATA\\\\tweets_#patriots.txt',encoding=\"utf8\")\n",
    "\n",
    "line = f.readline()\n",
    "\n",
    "\n",
    "tweet_p_followers = []\n",
    "tweet_p_pdate = []\n",
    "tweet_p_rcount = []\n",
    "tweet_p_imp = []\n",
    "tweet_p_rank = []\n",
    "tweet_p_cite = []\n",
    "user_id_p = []\n",
    "\n",
    "\n",
    "while len(line)!=0:\n",
    "    tweet = json.loads(line)\n",
    "    tweet_p_followers.append(tweet['tweet']['user']['followers_count'])\n",
    "    tweet_p_pdate.append(tweet['firstpost_date'])\n",
    "    tweet_p_rcount.append(tweet['metrics']['citations']['total'])\n",
    "    tweet_p_imp.append(tweet['metrics']['impressions'])\n",
    "    tweet_p_rank.append(tweet['metrics']['ranking_score'])\n",
    "    tweet_p_cite.append(tweet['tweet']['retweet_count'])\n",
    "    user_id_p.append(tweet['tweet']['user']['id'])\n",
    "    line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499.42105160280914\n",
      "1859.699282282715\n",
      "1.7828136071535776\n"
     ]
    }
   ],
   "source": [
    "# Patriots stats\n",
    "\n",
    "numtweets_p = len(tweet_p_followers)\n",
    "import numpy as np\n",
    "p,ind_p = np.unique(user_id_p,return_index=True)\n",
    "\n",
    "\n",
    "\n",
    "start_time_p = tweet_p_pdate[0]\n",
    "end_time_p = tweet_p_pdate[numtweets_p - 1]\n",
    "duration_p = (end_time_p - start_time_p)/3600\n",
    "\n",
    "num_followers_p = 0\n",
    "num_retweets_p = 0\n",
    "\n",
    "for i in range(0,numtweets_p - 1):\n",
    "    \n",
    "    num_retweets_p = num_retweets_p + tweet_p_rcount[i]\n",
    "\n",
    "tweet_p_unique =  [tweet_p_followers[i] for i in ind_p]\n",
    "avg_num_tweets_p = numtweets_p / duration_p\n",
    "avg_num_followers_p = sum(tweet_p_unique) / len(p) \n",
    "avg_num_retweets_p = num_retweets_p / numtweets_p\n",
    "\n",
    "print(avg_num_tweets_p)\n",
    "print(avg_num_followers_p)\n",
    "print(avg_num_retweets_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the nfl dataset\n",
    "# Features imported are number of followers, posting date of the tweet, retweet count\n",
    "\n",
    "import json\n",
    "import datetime, time\n",
    "\n",
    "\n",
    "f = open('C:\\\\Users\\\\Chandan\\\\Desktop\\\\DATA\\\\tweets_#nfl.txt',encoding=\"utf8\")\n",
    "\n",
    "line = f.readline()\n",
    "\n",
    "\n",
    "tweet_n_followers = []\n",
    "tweet_n_pdate = []\n",
    "tweet_n_rcount = []\n",
    "tweet_n_imp = []\n",
    "tweet_n_rank = []\n",
    "tweet_n_cite = []\n",
    "user_id_n = []\n",
    "\n",
    "while len(line)!=0:\n",
    "    tweet = json.loads(line)\n",
    "    tweet_n_followers.append(tweet['tweet']['user']['followers_count'])\n",
    "    tweet_n_pdate.append(tweet['firstpost_date'])\n",
    "    tweet_n_rcount.append(tweet['metrics']['citations']['total'])\n",
    "    tweet_n_imp.append(tweet['metrics']['impressions'])\n",
    "    tweet_n_rank.append(tweet['metrics']['ranking_score'])\n",
    "    tweet_n_cite.append(tweet['tweet']['retweet_count'])\n",
    "    user_id_n.append(tweet['tweet']['user']['id'])\n",
    "    line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279.55138019452266\n",
      "4376.644950576716\n",
      "1.538529248254988\n"
     ]
    }
   ],
   "source": [
    "# NFL stats\n",
    "\n",
    "numtweets_n = len(tweet_n_followers)\n",
    "import numpy as np\n",
    "n,ind_n = np.unique(user_id_n,return_index=True)\n",
    "\n",
    "start_time_n = tweet_n_pdate[0]\n",
    "end_time_n = tweet_n_pdate[numtweets_n - 1]\n",
    "duration_n = (end_time_n - start_time_n)/3600\n",
    "\n",
    "num_followers_n = 0\n",
    "num_retweets_n = 0\n",
    "\n",
    "for i in range(0,numtweets_n - 1):\n",
    "\n",
    "    num_retweets_n = num_retweets_n + tweet_n_rcount[i]\n",
    "\n",
    "tweet_n_unique =  [tweet_n_followers[i] for i in ind_n]\n",
    "avg_num_tweets_n = numtweets_n / duration_n\n",
    "avg_num_followers_n = sum(tweet_n_unique) / len(n) \n",
    "avg_num_retweets_n = num_retweets_n / numtweets_n\n",
    "\n",
    "print(avg_num_tweets_n)\n",
    "print(avg_num_followers_n)\n",
    "print(avg_num_retweets_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the sb49 dataset\n",
    "# Features imported are number of followers, posting date of the tweet, retweet count\n",
    "\n",
    "import json\n",
    "import datetime, time\n",
    "\n",
    "\n",
    "f = open('C:\\\\Users\\\\Chandan\\\\Desktop\\\\DATA\\\\tweets_#sb49.txt',encoding=\"utf8\")\n",
    "\n",
    "line = f.readline()\n",
    "\n",
    "\n",
    "tweet_sb_followers = []\n",
    "tweet_sb_pdate = []\n",
    "tweet_sb_rcount = []\n",
    "tweet_sb_imp = []\n",
    "tweet_sb_rank = []\n",
    "tweet_sb_cite = []\n",
    "user_id_sb = []\n",
    "\n",
    "\n",
    "\n",
    "while len(line)!=0:\n",
    "    tweet = json.loads(line)\n",
    "    tweet_sb_followers.append(tweet['tweet']['user']['followers_count'])\n",
    "    tweet_sb_pdate.append(tweet['firstpost_date'])\n",
    "    tweet_sb_rcount.append(tweet['metrics']['citations']['total'])\n",
    "    tweet_sb_imp.append(tweet['metrics']['impressions'])\n",
    "    tweet_sb_rank.append(tweet['metrics']['ranking_score'])\n",
    "    tweet_sb_cite.append(tweet['tweet']['retweet_count'])\n",
    "    user_id_sb.append(tweet['tweet']['user']['id'])\n",
    "    line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1419.8879074871902\n",
      "2243.8264617856307\n",
      "2.5111475770632117\n"
     ]
    }
   ],
   "source": [
    "# sb49 stats\n",
    "\n",
    "numtweets_sb = len(tweet_sb_followers)\n",
    "import numpy as np\n",
    "sb,ind_sb = np.unique(user_id_sb,return_index=True)\n",
    "\n",
    "start_time_sb = tweet_sb_pdate[0]\n",
    "end_time_sb = tweet_sb_pdate[numtweets_sb - 1]\n",
    "duration_sb = (end_time_sb - start_time_sb)/3600\n",
    "\n",
    "num_followers_sb = 0\n",
    "num_retweets_sb = 0\n",
    "\n",
    "for i in range(0,numtweets_sb - 1):\n",
    "    \n",
    "    num_retweets_sb = num_retweets_sb + tweet_sb_rcount[i]\n",
    "\n",
    "tweet_sb_unique =  [tweet_sb_followers[i] for i in ind_sb]\n",
    "avg_num_tweets_sb = numtweets_sb / duration_sb\n",
    "avg_num_followers_sb = sum(tweet_sb_unique) / len(sb) \n",
    "avg_num_retweets_sb = num_retweets_sb / numtweets_sb\n",
    "\n",
    "print(avg_num_tweets_sb)\n",
    "print(avg_num_followers_sb)\n",
    "print(avg_num_retweets_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the superbowl dataset\n",
    "# Features imported are number of followers, posting date of the tweet, retweet count\n",
    "\n",
    "import json\n",
    "import datetime, time\n",
    "\n",
    "\n",
    "f = open('C:\\\\Users\\\\Chandan\\\\Desktop\\\\DATA\\\\tweets_#superbowl.txt',encoding=\"utf8\")\n",
    "\n",
    "line = f.readline()\n",
    "\n",
    "\n",
    "tweet_s_followers = []\n",
    "tweet_s_pdate = []\n",
    "tweet_s_rcount = []\n",
    "tweet_s_imp = []\n",
    "tweet_s_rank = []\n",
    "tweet_s_cite = []\n",
    "user_id_s = []\n",
    "\n",
    "\n",
    "\n",
    "while len(line)!=0:\n",
    "    tweet = json.loads(line)\n",
    "    tweet_s_followers.append(tweet['tweet']['user']['followers_count'])\n",
    "    tweet_s_pdate.append(tweet['firstpost_date'])\n",
    "    tweet_s_rcount.append(tweet['metrics']['citations']['total'])\n",
    "    tweet_s_imp.append(tweet['metrics']['impressions'])\n",
    "    tweet_s_rank.append(tweet['metrics']['ranking_score'])\n",
    "    tweet_s_cite.append(tweet['tweet']['retweet_count'])\n",
    "    user_id_s.append(tweet['tweet']['user']['id'])\n",
    "    line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1401.245593656886\n",
      "4221.380655076919\n",
      "2.388269434231413\n"
     ]
    }
   ],
   "source": [
    "# Superbowl stats\n",
    "\n",
    "numtweets_s = len(tweet_s_followers)\n",
    "import numpy as np\n",
    "s,ind_s = np.unique(user_id_s,return_index=True)\n",
    "\n",
    "start_time_s = tweet_s_pdate[0]\n",
    "end_time_s = tweet_s_pdate[numtweets_s - 1]\n",
    "duration_s = (end_time_s - start_time_s)/3600\n",
    "\n",
    "num_followers_s = 0\n",
    "num_retweets_s = 0\n",
    "\n",
    "for i in range(0,numtweets_s - 1):\n",
    "    \n",
    "    num_retweets_s = num_retweets_s + tweet_s_rcount[i]\n",
    "    \n",
    "\n",
    "tweet_s_unique =  [tweet_s_followers[i] for i in ind_s]\n",
    "avg_num_tweets_s = numtweets_s / duration_s\n",
    "avg_num_followers_s = sum(tweet_s_unique) / len(s) \n",
    "avg_num_retweets_s = num_retweets_s / numtweets_s\n",
    "\n",
    "print(avg_num_tweets_s)\n",
    "print(avg_num_followers_s)\n",
    "print(avg_num_retweets_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.27718677e-21 2.83428669e-07 2.64964601e-01 3.33023267e-02\n",
      " 9.27150669e-01 9.86945203e-01 9.97048587e-01 9.71243384e-01\n",
      " 9.24811208e-01 9.10432752e-01 7.17506680e-01 4.41230218e-01\n",
      " 3.30288444e-01 2.58783791e-01 1.48531357e-01 2.18384256e-03\n",
      " 4.63123790e-01 2.04111382e-01 2.07929838e-02 5.39920370e-06\n",
      " 1.04322023e-01 4.90643504e-01 3.28812391e-01 6.36487552e-01\n",
      " 4.98790632e-01 3.85553041e-01 8.11325119e-01 9.59122373e-01]\n",
      "<bound method LikelihoodModelResults.t_test of <statsmodels.regression.linear_model.OLSResults object at 0x0000011F8EE11C08>>\n",
      "147.93021857118094\n",
      "0.010172562733401946\n",
      "11323.656959940748\n",
      "1\n",
      "17563\n",
      "194.1517027863777\n"
     ]
    }
   ],
   "source": [
    "# Hawks \n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from itertools import repeat\n",
    "\n",
    "num_tweets_hawks = 0\n",
    "num_retweets_hawks = 0\n",
    "num_followers_hawks = 0\n",
    "max_followers_hawks = 0\n",
    "\n",
    "window_hawks = 1\n",
    "start_time_hawks = tweet_hawks_pdate[0]\n",
    "end_time_hawks = start_time_hawks + window_hawks*3600\n",
    "\n",
    "feature_hawks = []\n",
    "feature_hawks_window = []\n",
    "feature_hawks_window.append(1)\n",
    "\n",
    "predict_hawks = []\n",
    "\n",
    "\n",
    "for i in range(0,numtweets_hawks - 1):\n",
    "    \n",
    "    if tweet_hawks_pdate[i] < end_time_hawks:\n",
    "        num_tweets_hawks = num_tweets_hawks + 1\n",
    "        num_retweets_hawks = num_retweets_hawks + tweet_hawks_rcount[i]\n",
    "        num_followers_hawks = num_followers_hawks + tweet_hawks_followers[i]\n",
    "        \n",
    "        if tweet_hawks_followers[i] > max_followers_hawks:\n",
    "            max_followers_hawks = tweet_hawks_followers[i]\n",
    "    \n",
    "    else:\n",
    "        feature_hawks_window.append(num_tweets_hawks)\n",
    "        predict_hawks.append(num_tweets_hawks)\n",
    "        num_tweets_hawks = 1\n",
    "        \n",
    "        feature_hawks_window.append(num_retweets_hawks)\n",
    "        num_retweets_hawks = tweet_hawks_rcount[i]\n",
    "        \n",
    "        feature_hawks_window.append(num_followers_hawks)\n",
    "        num_followers_hawks = tweet_hawks_followers[i]\n",
    "        \n",
    "        feature_hawks_window.append(max_followers_hawks)\n",
    "        max_followers_hawks = tweet_hawks_followers[i]\n",
    "        \n",
    "        feature_hawks_window = feature_hawks_window + list(repeat(0,24))\n",
    "        time_index_hawks = int(datetime.datetime.fromtimestamp(tweet_hawks_pdate[i]).strftime(\"%H\"))\n",
    "        feature_hawks_window[6+(time_index_hawks-1)] = 1\n",
    "        \n",
    "    \n",
    "        end_time_hawks = end_time_hawks + window_hawks*3600\n",
    "        \n",
    "        feature_hawks_window.pop(0) # new\n",
    "        feature_hawks.append(feature_hawks_window)\n",
    "        feature_hawks_window = []\n",
    "        feature_hawks_window.append(1)\n",
    "        \n",
    "\n",
    "predict_hawks = collections.deque(predict_hawks)\n",
    "predict_hawks.rotate(-1)\n",
    "predict_hawks = list(predict_hawks)# Ground truth\n",
    "\n",
    "\n",
    "hawk_model_linear_1 = sm.OLS(predict_hawks,feature_hawks).fit()\n",
    "\n",
    "# P-value and t-value\n",
    "\n",
    "print(hawk_model_linear_1.pvalues)\n",
    "print(hawk_model_linear_1.t_test)\n",
    "#print(hawk_model_linear_1.tvalues)\n",
    "#print(hawk_model_linear_1.rsquared)\n",
    "#print(hawk_model_linear_1.summary())\n",
    "\n",
    "# Using sci-kit for training accuracy\n",
    "\n",
    "hawk_model_linear_2 = linear_model.LinearRegression()\n",
    "hawk_model_linear_2.fit(feature_hawks,predict_hawks)\n",
    "\n",
    "predicted_hawks = hawk_model_linear_2.predict(feature_hawks) # Predicted values\n",
    "abs_error_hawks = abs(predict_hawks - predicted_hawks)\n",
    "mean_abs_error_hawks = mean_absolute_error(predict_hawks,predicted_hawks)\n",
    "\n",
    "print(mean_abs_error_hawks)\n",
    "print(min(abs_error_hawks))\n",
    "print(max(abs_error_hawks))\n",
    "print(min(predict_hawks))\n",
    "print(max(predict_hawks))\n",
    "print(np.mean(predict_hawks))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.01035559e-01   4.95208974e-12   6.74453208e-27   1.29532395e-13\n",
      "   1.82913518e-07   9.86742747e-01   9.49503418e-01   9.73260951e-01\n",
      "   9.38663700e-01   9.82616468e-01   9.96657532e-01   9.95001225e-01\n",
      "   9.66801462e-01   8.64128029e-01   9.14340836e-01   2.84594386e-01\n",
      "   8.88442147e-01   8.39960860e-01   8.03184613e-01   7.86281440e-02\n",
      "   1.66800862e-02   1.19357844e-01   9.29048389e-01   1.35923391e-02\n",
      "   1.26154814e-03   6.08176596e-01   7.65365189e-01   9.41233086e-01\n",
      "   9.68747577e-01]\n",
      "<bound method LikelihoodModelResults.t_test of <statsmodels.regression.linear_model.OLSResults object at 0x116f98e80>>\n",
      "[ -6.73281381e-01  -7.05406222e+00   1.12977982e+01  -7.58804632e+00\n",
      "   5.27977797e+00   1.66234084e-02   6.33577077e-02   3.35331205e-02\n",
      "  -7.69827803e-02  -2.17981166e-02   4.19097507e-03   6.26776799e-03\n",
      "   4.16381223e-02  -1.71197433e-01  -1.07611656e-01  -1.07104224e+00\n",
      "   1.40337176e-01   2.02033850e-01  -2.49341489e-01   1.76179950e+00\n",
      "   2.40062328e+00  -1.55976990e+00   8.90807394e-02   2.47539825e+00\n",
      "  -3.24044464e+00  -5.12956204e-01  -2.98582506e-01  -7.37519693e-02\n",
      "   3.91959835e-02]\n",
      "0.547236390636\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.547\n",
      "Model:                            OLS   Adj. R-squared:                  0.526\n",
      "Method:                 Least Squares   F-statistic:                     26.05\n",
      "Date:                Wed, 16 Mar 2016   Prob (F-statistic):           1.95e-82\n",
      "Time:                        18:45:24   Log-Likelihood:                -4129.1\n",
      "No. Observations:                 610   AIC:                             8314.\n",
      "Df Residuals:                     582   BIC:                             8438.\n",
      "Df Model:                          27                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const         -6.0117      8.929     -0.673      0.501       -23.549    11.525\n",
      "x1            -2.0867      0.296     -7.054      0.000        -2.668    -1.506\n",
      "x2             3.2077      0.284     11.298      0.000         2.650     3.765\n",
      "x3            -0.0011      0.000     -7.588      0.000        -0.001    -0.001\n",
      "x4             0.0008      0.000      5.280      0.000         0.001     0.001\n",
      "x5             0.8998     54.130      0.017      0.987      -105.414   107.214\n",
      "x6             3.3239     52.462      0.063      0.950       -99.714   106.361\n",
      "x7             1.7081     50.937      0.034      0.973       -98.335   101.751\n",
      "x8            -3.9207     50.929     -0.077      0.939      -103.948    96.107\n",
      "x9            -0.9048     41.508     -0.022      0.983       -82.428    80.619\n",
      "x10            0.1845     44.017      0.004      0.997       -86.267    86.636\n",
      "x11            0.2357     37.608      0.006      0.995       -73.627    74.099\n",
      "x12            1.6683     40.066      0.042      0.967       -77.023    80.360\n",
      "x13           -6.8578     40.058     -0.171      0.864       -85.533    71.817\n",
      "x14           -4.3103     40.055     -0.108      0.914       -82.980    74.359\n",
      "x15          -43.8515     40.943     -1.071      0.285      -124.265    36.562\n",
      "x16            5.2796     37.621      0.140      0.888       -68.609    79.168\n",
      "x17            7.7169     38.196      0.202      0.840       -67.302    82.736\n",
      "x18           -9.9241     39.801     -0.249      0.803       -88.096    68.248\n",
      "x19           64.3976     36.552      1.762      0.079        -7.393   136.188\n",
      "x20          112.2291     46.750      2.401      0.017        20.410   204.048\n",
      "x21          -55.9495     35.870     -1.560      0.119      -126.401    14.502\n",
      "x22            3.3604     37.723      0.089      0.929       -70.729    77.450\n",
      "x23           92.1268     37.217      2.475      0.014        19.031   165.223\n",
      "x24         -135.6672     41.867     -3.240      0.001      -217.896   -53.439\n",
      "x25          -21.6972     42.298     -0.513      0.608      -104.773    61.379\n",
      "x26          -14.7894     49.532     -0.299      0.765      -112.073    82.494\n",
      "x27           -3.3915     45.985     -0.074      0.941       -93.708    86.925\n",
      "x28            2.1217     54.130      0.039      0.969      -104.192   108.436\n",
      "==============================================================================\n",
      "Omnibus:                      870.645   Durbin-Watson:                   2.311\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           458169.128\n",
      "Skew:                           7.218   Prob(JB):                         0.00\n",
      "Kurtosis:                     136.484   Cond. No.                     6.17e+21\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 3.94e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "59.3347206486\n",
      "0.012047351719\n",
      "3408.7316163\n",
      "1\n",
      "5136\n",
      "43.0\n"
     ]
    }
   ],
   "source": [
    "# GO Patriots \n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "num_tweets_gp = 0\n",
    "num_retweets_gp = 0\n",
    "num_followers_gp = 0\n",
    "max_followers_gp = 0\n",
    "\n",
    "window_gp = 1\n",
    "start_time_gp = tweet_gp_pdate[0]\n",
    "end_time_gp = start_time_gp + window_gp*3600\n",
    "\n",
    "feature_gp = []\n",
    "feature_gp_window = []\n",
    "feature_gp_window.append(1)\n",
    "\n",
    "predict_gp = []\n",
    "\n",
    "for i in range(0,numtweets_gp - 1):\n",
    "    \n",
    "    if tweet_gp_pdate[i] < end_time_gp:\n",
    "        num_tweets_gp = num_tweets_gp + 1\n",
    "        num_retweets_gp = num_retweets_gp + tweet_gp_rcount[i]\n",
    "        num_followers_gp = num_followers_gp + tweet_gp_followers[i]\n",
    "        \n",
    "        if tweet_gp_followers[i] > max_followers_gp:\n",
    "            max_followers_gp = tweet_gp_followers[i]\n",
    "    \n",
    "    else:\n",
    "        feature_gp_window.append(num_tweets_gp)\n",
    "        predict_gp.append(num_tweets_gp)\n",
    "        num_tweets_gp = 1\n",
    "        \n",
    "        feature_gp_window.append(num_retweets_gp)\n",
    "        num_retweets_gp = tweet_gp_rcount[i]\n",
    "        \n",
    "        feature_gp_window.append(num_followers_gp)\n",
    "        num_followers_gp = tweet_gp_followers[i]\n",
    "        \n",
    "        feature_gp_window.append(max_followers_gp)\n",
    "        max_followers_gp = tweet_gp_followers[i]\n",
    "        \n",
    "        feature_gp_window = feature_gp_window + list(repeat(0,24))\n",
    "        time_index_gp = int(datetime.datetime.fromtimestamp(tweet_gp_pdate[i]).strftime(\"%H\"))\n",
    "        feature_gp_window[6+(time_index_gp-1)] = 1\n",
    "        \n",
    "        \n",
    "        end_time_gp = end_time_gp + window_gp*3600\n",
    "        \n",
    "        feature_gp.append(feature_gp_window)\n",
    "        feature_gp_window = []\n",
    "        feature_gp_window.append(1)\n",
    "        \n",
    "\n",
    "predict_gp = collections.deque(predict_gp)\n",
    "predict_gp.rotate(-1)\n",
    "predict_gp = list(predict_gp) # Ground truth\n",
    "\n",
    "gp_model_linear_1 = sm.OLS(predict_gp,feature_gp).fit()\n",
    "\n",
    "# P-value and t-value\n",
    "\n",
    "print(gp_model_linear_1.pvalues)\n",
    "print(gp_model_linear_1.t_test)\n",
    "print(gp_model_linear_1.tvalues)\n",
    "print(gp_model_linear_1.rsquared)\n",
    "print(gp_model_linear_1.summary())\n",
    "\n",
    "# Using sci-kit for training accuracy\n",
    "\n",
    "gp_model_linear_2 = linear_model.LinearRegression(fit_intercept=False)\n",
    "gp_model_linear_2.fit(feature_gp,predict_gp)\n",
    "\n",
    "predicted_gp = gp_model_linear_2.predict(feature_gp) # Predicted values\n",
    "abs_error_gp = abs(predict_gp - predicted_gp)\n",
    "mean_abs_error_gp = mean_absolute_error(predict_gp,predicted_gp)\n",
    "\n",
    "print(mean_abs_error_gp)\n",
    "print(min(abs_error_gp))\n",
    "print(max(abs_error_gp))\n",
    "print(min(predict_gp))\n",
    "print(max(predict_gp))\n",
    "print(np.mean(predict_gp))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.55119825e-02   1.29895219e-40   7.41398459e-06   1.21032009e-01\n",
      "   4.70380108e-03   5.61297183e-01   6.30842119e-01   5.95974367e-01\n",
      "   8.20790068e-01   6.36369668e-01   5.76208763e-01   6.28679715e-01\n",
      "   7.50649998e-01   9.44687035e-01   8.76668311e-01   6.68200460e-02\n",
      "   1.41711293e-03   2.25020124e-01   2.67499601e-01   9.90289930e-01\n",
      "   2.22087999e-01   2.31116988e-01   7.81064882e-01   5.93195442e-04\n",
      "   1.22954582e-01   5.94467388e-01   7.95995235e-01   8.19800663e-01\n",
      "   7.01783144e-01]\n",
      "<bound method LikelihoodModelResults.t_test of <statsmodels.regression.linear_model.OLSResults object at 0x116f98cc0>>\n",
      "[  2.00252332e+00   1.39966529e+01  -4.50640283e+00  -1.55184505e+00\n",
      "   2.83334279e+00  -5.81120136e-01  -4.80697432e-01  -5.30377027e-01\n",
      "  -2.26591537e-01  -4.72932771e-01  -5.59123961e-01  -4.83742890e-01\n",
      "   3.17874397e-01   6.93984707e-02   1.55235871e-01   1.83498542e+00\n",
      "   3.20054951e+00  -1.21407596e+00  -1.10948937e+00   1.21732690e-02\n",
      "   1.22179481e+00  -1.19825320e+00  -2.78010300e-01   3.44629677e+00\n",
      "  -1.54386144e+00  -5.32553089e-01  -2.58605970e-01  -2.27864371e-01\n",
      "  -3.83029966e-01]\n",
      "0.725236871958\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.725\n",
      "Model:                            OLS   Adj. R-squared:                  0.717\n",
      "Method:                 Least Squares   F-statistic:                     92.97\n",
      "Date:                Wed, 16 Mar 2016   Prob (F-statistic):          6.20e-245\n",
      "Time:                        18:51:29   Log-Likelihood:                -8725.8\n",
      "No. Observations:                 979   AIC:                         1.751e+04\n",
      "Df Residuals:                     951   BIC:                         1.764e+04\n",
      "Df Model:                          27                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const        131.1644     65.500      2.003      0.046         2.624   259.705\n",
      "x1             1.4797      0.106     13.997      0.000         1.272     1.687\n",
      "x2            -0.4292      0.095     -4.506      0.000        -0.616    -0.242\n",
      "x3         -3.346e-05   2.16e-05     -1.552      0.121     -7.58e-05  8.85e-06\n",
      "x4             0.0002   7.32e-05      2.833      0.005      6.38e-05     0.000\n",
      "x5          -157.6109    271.219     -0.581      0.561      -689.868   374.646\n",
      "x6          -131.8706    274.332     -0.481      0.631      -670.236   406.495\n",
      "x7          -129.6321    244.415     -0.530      0.596      -609.287   350.023\n",
      "x8           -59.5382    262.756     -0.227      0.821      -575.186   456.110\n",
      "x9          -103.8675    219.624     -0.473      0.636      -534.872   327.137\n",
      "x10         -111.7643    199.892     -0.559      0.576      -504.044   280.516\n",
      "x11          -95.0330    196.454     -0.484      0.629      -480.566   290.500\n",
      "x12           98.9821    311.387      0.318      0.751      -512.104   710.068\n",
      "x13           22.5479    324.905      0.069      0.945      -615.065   660.161\n",
      "x14           48.8908    314.945      0.155      0.877      -569.177   666.958\n",
      "x15          507.2566    276.436      1.835      0.067       -35.239  1049.752\n",
      "x16          995.3200    310.984      3.201      0.001       385.026  1605.614\n",
      "x17         -373.2393    307.427     -1.214      0.225      -976.552   230.074\n",
      "x18         -345.8107    311.685     -1.109      0.267      -957.480   265.858\n",
      "x19            3.7514    308.163      0.012      0.990      -601.008   608.510\n",
      "x20          386.8913    316.658      1.222      0.222      -234.538  1008.321\n",
      "x21         -374.0655    312.176     -1.198      0.231      -986.698   238.567\n",
      "x22          -76.2459    274.256     -0.278      0.781      -614.462   461.970\n",
      "x23         1040.3255    301.868      3.446      0.001       447.922  1632.729\n",
      "x24         -537.3357    348.047     -1.544      0.123     -1220.364   145.692\n",
      "x25         -167.8516    315.183     -0.533      0.594      -786.386   450.683\n",
      "x26          -90.3555    349.395     -0.259      0.796      -776.029   595.318\n",
      "x27          -82.5027    362.069     -0.228      0.820      -793.050   628.045\n",
      "x28         -136.0776    355.266     -0.383      0.702      -833.274   561.119\n",
      "==============================================================================\n",
      "Omnibus:                     1725.499   Durbin-Watson:                   1.853\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1477094.788\n",
      "Skew:                          11.707   Prob(JB):                         0.00\n",
      "Kurtosis:                     191.845   Cond. No.                     1.77e+21\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.52e-26. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "406.281379729\n",
      "0.00662351582983\n",
      "30047.3761773\n",
      "1\n",
      "54301\n",
      "500.213483146\n"
     ]
    }
   ],
   "source": [
    "# Patriots \n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "num_tweets_p = 0\n",
    "num_retweets_p = 0\n",
    "num_followers_p = 0\n",
    "max_followers_p = 0\n",
    "\n",
    "window_p = 1\n",
    "start_time_p = tweet_p_pdate[0]\n",
    "end_time_p = start_time_p + window_p*3600\n",
    "\n",
    "feature_p = []\n",
    "feature_p_window = []\n",
    "feature_p_window.append(1)\n",
    "\n",
    "predict_p = []\n",
    "\n",
    "for i in range(0,numtweets_p - 1):\n",
    "    \n",
    "    if tweet_p_pdate[i] < end_time_p:\n",
    "        num_tweets_p = num_tweets_p + 1\n",
    "        num_retweets_p = num_retweets_p + tweet_p_rcount[i]\n",
    "        num_followers_p = num_followers_p + tweet_p_followers[i]\n",
    "        \n",
    "        if tweet_p_followers[i] > max_followers_p:\n",
    "            max_followers_p = tweet_p_followers[i]\n",
    "    \n",
    "    else:\n",
    "        feature_p_window.append(num_tweets_p)\n",
    "        predict_p.append(num_tweets_p)\n",
    "        num_tweets_p = 1\n",
    "        \n",
    "        feature_p_window.append(num_retweets_p)\n",
    "        num_retweets_p = tweet_p_rcount[i]\n",
    "        \n",
    "        feature_p_window.append(num_followers_p)\n",
    "        num_followers_p = tweet_p_followers[i]\n",
    "        \n",
    "        feature_p_window.append(max_followers_p)\n",
    "        max_followers_p = tweet_p_followers[i]\n",
    "        \n",
    "        \n",
    "        feature_p_window = feature_p_window + list(repeat(0,24))\n",
    "        time_index_p = int(datetime.datetime.fromtimestamp(tweet_p_pdate[i]).strftime(\"%H\"))\n",
    "        feature_p_window[6+(time_index_p-1)] = 1\n",
    "        \n",
    "        \n",
    "        end_time_p = end_time_p + window_p*3600\n",
    "        \n",
    "        feature_p.append(feature_p_window)\n",
    "        feature_p_window = []\n",
    "        feature_p_window.append(1)\n",
    "        \n",
    "\n",
    "predict_p = collections.deque(predict_p)\n",
    "predict_p.rotate(-1)\n",
    "predict_p = list(predict_p) # Ground truth\n",
    "\n",
    "p_model_linear_1 = sm.OLS(predict_p,feature_p).fit()\n",
    "\n",
    "# P-value and t-value\n",
    "\n",
    "print(p_model_linear_1.pvalues)\n",
    "print(p_model_linear_1.t_test)\n",
    "print(p_model_linear_1.tvalues)\n",
    "print(p_model_linear_1.rsquared)\n",
    "print(p_model_linear_1.summary())\n",
    "\n",
    "# Using sci-kit for training accuracy\n",
    "\n",
    "p_model_linear_2 = linear_model.LinearRegression(fit_intercept=False)\n",
    "p_model_linear_2.fit(feature_p,predict_p)\n",
    "\n",
    "predicted_p = p_model_linear_2.predict(feature_p) # Predicted values\n",
    "abs_error_p = abs(predict_p - predicted_p)\n",
    "mean_abs_error_p = mean_absolute_error(predict_p,predicted_p)\n",
    "\n",
    "\n",
    "print(mean_abs_error_p)\n",
    "print(min(abs_error_p))\n",
    "print(max(abs_error_p))\n",
    "print(min(predict_p))\n",
    "print(max(predict_p))\n",
    "print(np.mean(predict_p))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.22059724e-12   4.40322430e-02   8.84215597e-01   6.29847723e-19\n",
      "   5.04238527e-14   4.06087689e-02   3.87928457e-02   3.59871488e-02\n",
      "   2.50682617e-02   4.64764910e-02   6.35614768e-01   1.46838135e-01\n",
      "   4.49620148e-01   8.11487769e-01   6.03039064e-01   4.54665697e-01\n",
      "   4.77163201e-02   9.85866765e-01   8.89780852e-01   1.03266599e-02\n",
      "   9.84819943e-06   1.51136739e-01   7.71508693e-01   1.07640050e-03\n",
      "   4.34329029e-04   1.85393663e-01   8.52429948e-01   4.47207561e-01\n",
      "   4.77398646e-01]\n",
      "<bound method LikelihoodModelResults.t_test of <statsmodels.regression.linear_model.OLSResults object at 0x11a461f60>>\n",
      "[ 7.02526787  2.01662182  0.14566873  9.08826873 -7.65348529 -2.05046639\n",
      " -2.06941351 -2.10022849 -2.24410944 -1.99379539 -0.47400051  1.45204587\n",
      "  0.75637938 -0.23857734  0.52021915  0.74798391  1.98260167  0.01771924\n",
      " -0.13862084  2.57011602  4.44588557 -1.43675212  0.29048971  3.28043065\n",
      " -3.53144309 -1.32534553  0.18607248 -0.76041266 -0.71079048]\n",
      "0.739076200382\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.739\n",
      "Model:                            OLS   Adj. R-squared:                  0.731\n",
      "Method:                 Least Squares   F-statistic:                     94.21\n",
      "Date:                Wed, 16 Mar 2016   Prob (F-statistic):          2.39e-240\n",
      "Time:                        19:04:08   Log-Likelihood:                -6781.7\n",
      "No. Observations:                 926   AIC:                         1.362e+04\n",
      "Df Residuals:                     898   BIC:                         1.375e+04\n",
      "Df Model:                          27                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const        113.7283     16.188      7.025      0.000        81.957   145.500\n",
      "x1             0.2227      0.110      2.017      0.044         0.006     0.439\n",
      "x2             0.0079      0.054      0.146      0.884        -0.099     0.114\n",
      "x3             0.0001   1.59e-05      9.088      0.000         0.000     0.000\n",
      "x4            -0.0002   2.25e-05     -7.653      0.000        -0.000    -0.000\n",
      "x5           -86.4497     42.161     -2.050      0.041      -169.195    -3.704\n",
      "x6           -90.2729     43.622     -2.069      0.039      -175.887    -4.659\n",
      "x7           -89.5013     42.615     -2.100      0.036      -173.138    -5.865\n",
      "x8           -91.3593     40.711     -2.244      0.025      -171.259   -11.460\n",
      "x9           -82.0896     41.173     -1.994      0.046      -162.895    -1.284\n",
      "x10          -33.2088     70.061     -0.474      0.636      -170.710   104.293\n",
      "x11          107.6679     74.149      1.452      0.147       -37.858   253.194\n",
      "x12           52.9896     70.057      0.756      0.450       -84.505   190.484\n",
      "x13          -16.4232     68.838     -0.239      0.811      -151.526   118.679\n",
      "x14           35.8230     68.861      0.520      0.603       -99.325   170.971\n",
      "x15           51.4924     68.842      0.748      0.455       -83.617   186.601\n",
      "x16          141.5696     71.406      1.983      0.048         1.428   281.712\n",
      "x17            1.1616     65.556      0.018      0.986      -127.498   129.821\n",
      "x18           -9.5773     69.090     -0.139      0.890      -145.173   126.019\n",
      "x19          180.4490     70.210      2.570      0.010        42.653   318.245\n",
      "x20          317.7868     71.479      4.446      0.000       177.502   458.072\n",
      "x21         -105.6937     73.564     -1.437      0.151      -250.072    38.684\n",
      "x22           19.4658     67.010      0.290      0.772      -112.049   150.981\n",
      "x23          240.7700     73.396      3.280      0.001        96.723   384.817\n",
      "x24         -245.3896     69.487     -3.531      0.000      -381.765  -109.014\n",
      "x25          -92.9080     70.101     -1.325      0.185      -230.489    44.673\n",
      "x26           13.6174     73.184      0.186      0.852      -130.013   157.248\n",
      "x27          -55.3774     72.826     -0.760      0.447      -198.305    87.551\n",
      "x28          -50.8141     71.490     -0.711      0.477      -191.120    89.492\n",
      "==============================================================================\n",
      "Omnibus:                     1008.738   Durbin-Watson:                   1.971\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           378966.107\n",
      "Skew:                           4.540   Prob(JB):                         0.00\n",
      "Kurtosis:                     101.689   Cond. No.                     5.17e+21\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 5.18e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "130.685474328\n",
      "0.127124709827\n",
      "4855.34646989\n",
      "1\n",
      "11420\n",
      "279.719222462\n"
     ]
    }
   ],
   "source": [
    "# NFL\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "num_tweets_n = 0\n",
    "num_retweets_n = 0\n",
    "num_followers_n = 0\n",
    "max_followers_n = 0\n",
    "\n",
    "window_n = 1\n",
    "start_time_n = tweet_n_pdate[0]\n",
    "end_time_n = start_time_n + window_n*3600\n",
    "\n",
    "feature_n = []\n",
    "feature_n_window = []\n",
    "feature_n_window.append(1)\n",
    "\n",
    "predict_n = []\n",
    "\n",
    "for i in range(0,numtweets_n - 1):\n",
    "    \n",
    "    if tweet_n_pdate[i] < end_time_n:\n",
    "        num_tweets_n = num_tweets_n + 1\n",
    "        num_retweets_n = num_retweets_n + tweet_n_rcount[i]\n",
    "        num_followers_n = num_followers_n + tweet_n_followers[i]\n",
    "        \n",
    "        if tweet_n_followers[i] > max_followers_n:\n",
    "            max_followers_n = tweet_n_followers[i]\n",
    "    \n",
    "    else:\n",
    "        feature_n_window.append(num_tweets_n)\n",
    "        predict_n.append(num_tweets_n)\n",
    "        num_tweets_n = 1\n",
    "        \n",
    "        feature_n_window.append(num_retweets_n)\n",
    "        num_retweets_n = tweet_n_rcount[i]\n",
    "        \n",
    "        feature_n_window.append(num_followers_n)\n",
    "        num_followers_n = tweet_n_followers[i]\n",
    "        \n",
    "        feature_n_window.append(max_followers_n)\n",
    "        max_followers_n = tweet_n_followers[i]\n",
    "        \n",
    "        \n",
    "        feature_n_window = feature_n_window + list(repeat(0,24))\n",
    "        time_index_n = int(datetime.datetime.fromtimestamp(tweet_n_pdate[i]).strftime(\"%H\"))\n",
    "        feature_n_window[6+(time_index_n-1)] = 1\n",
    "        \n",
    "        \n",
    "        end_time_n = end_time_n + window_n*3600\n",
    "        \n",
    "        feature_n.append(feature_n_window)\n",
    "        feature_n_window = []\n",
    "        feature_n_window.append(1)\n",
    "        \n",
    "\n",
    "predict_n = collections.deque(predict_n)\n",
    "predict_n.rotate(-1)\n",
    "predict_n = list(predict_n) # Ground truth\n",
    "\n",
    "n_model_linear_1 = sm.OLS(predict_n,feature_n).fit()\n",
    "\n",
    "# P-value and t-value\n",
    "\n",
    "print(n_model_linear_1.pvalues)\n",
    "print(n_model_linear_1.t_test)\n",
    "print(n_model_linear_1.tvalues)\n",
    "print(n_model_linear_1.rsquared)\n",
    "print(n_model_linear_1.summary())\n",
    "\n",
    "# Using sci-kit for training accuracy\n",
    "\n",
    "n_model_linear_2 = linear_model.LinearRegression(fit_intercept=False)\n",
    "n_model_linear_2.fit(feature_n,predict_n)\n",
    "\n",
    "predicted_n = n_model_linear_2.predict(feature_n) # Predicted values\n",
    "abs_error_n = abs(predict_n - predicted_n)\n",
    "mean_abs_error_n = mean_absolute_error(predict_n,predicted_n)\n",
    "\n",
    "print(mean_abs_error_n)\n",
    "print(min(abs_error_n))\n",
    "print(max(abs_error_n))\n",
    "print(min(predict_n))\n",
    "print(max(predict_n))\n",
    "print(np.mean(predict_n))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.50136123e-01   8.83976766e-25   5.97135073e-02   4.50483690e-01\n",
      "   2.51416552e-05   8.78421061e-01   9.80503562e-01   8.84081023e-01\n",
      "   8.72112233e-01   8.75754038e-01   9.16697524e-01   9.75624710e-01\n",
      "   9.27585256e-01   9.72242904e-01   9.63737178e-01   8.28895369e-04\n",
      "   9.22602519e-02   1.09265673e-01   2.86970704e-01   8.10933224e-01\n",
      "   7.19941429e-01   4.40255503e-01   1.58596943e-01   7.31532953e-01\n",
      "   1.28859985e-01   8.51236721e-01   9.02873924e-01   7.18471099e-01\n",
      "   9.72415861e-01]\n",
      "<bound method LikelihoodModelResults.t_test of <statsmodels.regression.linear_model.OLSResults object at 0x11a461048>>\n",
      "[ -0.93511564  10.79343681  -1.88677299   0.75514367   4.24945083\n",
      "  -0.15304177  -0.02444863   0.145865     0.16105063   0.15642624\n",
      "   0.1046423   -0.03056845  -0.09092474   0.03481111  -0.04548493\n",
      "   3.36142012   1.68651182  -1.60408295  -1.06581687   0.23933645\n",
      "   0.35871973   0.77231791  -1.41170938  -0.34326018  -1.52088195\n",
      "  -0.18762832  -0.12208759  -0.36068677  -0.03459411]\n",
      "0.845055718232\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.845\n",
      "Model:                            OLS   Adj. R-squared:                  0.838\n",
      "Method:                 Least Squares   F-statistic:                     111.9\n",
      "Date:                Wed, 16 Mar 2016   Prob (F-statistic):          1.57e-204\n",
      "Time:                        19:12:06   Log-Likelihood:                -5646.1\n",
      "No. Observations:                 582   AIC:                         1.135e+04\n",
      "Df Residuals:                     554   BIC:                         1.147e+04\n",
      "Df Model:                          27                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const       -168.8930    180.612     -0.935      0.350      -523.661   185.875\n",
      "x1             1.1895      0.110     10.793      0.000         0.973     1.406\n",
      "x2            -0.1902      0.101     -1.887      0.060        -0.388     0.008\n",
      "x3          1.182e-05   1.57e-05      0.755      0.450     -1.89e-05  4.26e-05\n",
      "x4             0.0002   4.55e-05      4.249      0.000         0.000     0.000\n",
      "x5          -142.4449    930.758     -0.153      0.878     -1970.692  1685.802\n",
      "x6           -20.2399    827.854     -0.024      0.981     -1646.357  1605.877\n",
      "x7           126.2317    865.401      0.146      0.884     -1573.636  1826.099\n",
      "x8           139.3937    865.527      0.161      0.872     -1560.722  1839.509\n",
      "x9           129.6152    828.603      0.156      0.876     -1497.972  1757.202\n",
      "x10           90.4503    864.376      0.105      0.917     -1607.405  1788.306\n",
      "x11          -24.2866    794.499     -0.031      0.976     -1584.885  1536.312\n",
      "x12          -73.6583    810.102     -0.091      0.928     -1664.905  1517.588\n",
      "x13           22.9790    660.106      0.035      0.972     -1273.638  1319.596\n",
      "x14          -32.6277    717.329     -0.045      0.964     -1441.645  1376.390\n",
      "x15         2785.1494    828.563      3.361      0.001      1157.640  4412.659\n",
      "x16         1231.7337    730.344      1.687      0.092      -202.848  2666.316\n",
      "x17        -1398.6615    871.938     -1.604      0.109     -3111.371   314.048\n",
      "x18         -833.6473    782.167     -1.066      0.287     -2370.024   702.729\n",
      "x19          196.8693    822.563      0.239      0.811     -1418.854  1812.593\n",
      "x20          276.2018    769.965      0.359      0.720     -1236.207  1788.610\n",
      "x21          618.0368    800.236      0.772      0.440      -953.832  2189.905\n",
      "x22        -1128.2592    799.215     -1.412      0.159     -2698.121   441.603\n",
      "x23         -290.9994    847.752     -0.343      0.732     -1956.200  1374.201\n",
      "x24        -1257.7849    827.010     -1.521      0.129     -2882.244   366.674\n",
      "x25         -155.1473    826.886     -0.188      0.851     -1779.363  1469.069\n",
      "x26          -98.9176    810.218     -0.122      0.903     -1690.393  1492.558\n",
      "x27         -298.9775    828.912     -0.361      0.718     -1927.172  1329.217\n",
      "x28          -29.9028    864.391     -0.035      0.972     -1727.788  1667.982\n",
      "==============================================================================\n",
      "Omnibus:                      924.492   Durbin-Watson:                   1.382\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           591357.263\n",
      "Skew:                           8.875   Prob(JB):                         0.00\n",
      "Kurtosis:                     158.148   Cond. No.                     5.90e+21\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.25e-25. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "1064.93510044\n",
      "1.9699436951\n",
      "66165.4057076\n",
      "1\n",
      "110429\n",
      "1420.85051546\n"
     ]
    }
   ],
   "source": [
    "# sb49 \n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "num_tweets_sb = 0\n",
    "num_retweets_sb = 0\n",
    "num_followers_sb = 0\n",
    "max_followers_sb = 0\n",
    "\n",
    "window_sb = 1\n",
    "start_time_sb = tweet_sb_pdate[0]\n",
    "end_time_sb = start_time_sb + window_sb*3600\n",
    "\n",
    "feature_sb = []\n",
    "feature_sb_window = []\n",
    "feature_sb_window.append(1)\n",
    "\n",
    "predict_sb = []\n",
    "\n",
    "for i in range(0,numtweets_sb - 1):\n",
    "    \n",
    "    if tweet_sb_pdate[i] < end_time_sb:\n",
    "        num_tweets_sb = num_tweets_sb + 1\n",
    "        num_retweets_sb = num_retweets_sb + tweet_sb_rcount[i]\n",
    "        num_followers_sb = num_followers_sb + tweet_sb_followers[i]\n",
    "        \n",
    "        if tweet_sb_followers[i] > max_followers_sb:\n",
    "            max_followers_sb = tweet_sb_followers[i]\n",
    "    \n",
    "    else:\n",
    "        feature_sb_window.append(num_tweets_sb)\n",
    "        predict_sb.append(num_tweets_sb)\n",
    "        num_tweets_sb = 1\n",
    "        \n",
    "        feature_sb_window.append(num_retweets_sb)\n",
    "        num_retweets_sb = tweet_sb_rcount[i]\n",
    "        \n",
    "        feature_sb_window.append(num_followers_sb)\n",
    "        num_followers_sb = tweet_sb_followers[i]\n",
    "        \n",
    "        feature_sb_window.append(max_followers_sb)\n",
    "        max_followers_sb = tweet_sb_followers[i]\n",
    "        \n",
    "        \n",
    "        feature_sb_window = feature_sb_window + list(repeat(0,24))\n",
    "        time_index_sb = int(datetime.datetime.fromtimestamp(tweet_sb_pdate[i]).strftime(\"%H\"))\n",
    "        feature_sb_window[6+(time_index_sb-1)] = 1\n",
    "        \n",
    "        \n",
    "        end_time_sb = end_time_sb + window_sb*3600\n",
    "        \n",
    "        feature_sb.append(feature_sb_window)\n",
    "        feature_sb_window = []\n",
    "        feature_sb_window.append(1)\n",
    "        \n",
    "\n",
    "predict_sb = collections.deque(predict_sb)\n",
    "predict_sb.rotate(-1)\n",
    "predict_sb = list(predict_sb) # Ground truth\n",
    "\n",
    "sb_model_linear_1 = sm.OLS(predict_sb,feature_sb).fit()\n",
    "\n",
    "# P-value and t-value\n",
    "\n",
    "print(sb_model_linear_1.pvalues)\n",
    "print(sb_model_linear_1.t_test)\n",
    "print(sb_model_linear_1.tvalues)\n",
    "print(sb_model_linear_1.rsquared)\n",
    "print(sb_model_linear_1.summary())\n",
    "\n",
    "# Using sci-kit for training accuracy\n",
    "\n",
    "sb_model_linear_2 = linear_model.LinearRegression(fit_intercept=False)\n",
    "sb_model_linear_2.fit(feature_sb,predict_sb)\n",
    "\n",
    "predicted_sb = sb_model_linear_2.predict(feature_sb) # Predicted values\n",
    "abs_error_sb = abs(predict_sb - predicted_sb)\n",
    "mean_abs_error_sb = mean_absolute_error(predict_sb,predicted_sb)\n",
    "\n",
    "print(mean_abs_error_sb)\n",
    "print(min(abs_error_sb))\n",
    "print(max(abs_error_sb))\n",
    "print(min(predict_sb))\n",
    "print(max(predict_sb))\n",
    "print(np.mean(predict_sb))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7.55916137e-01   1.62571761e-20   1.87295304e-06   1.08924573e-02\n",
      "   1.98495363e-05   7.55593594e-01   7.68344269e-01   8.82056884e-01\n",
      "   9.78773061e-01   8.75193680e-01   9.33063038e-01   9.50990959e-01\n",
      "   9.59751373e-01   9.36712446e-01   9.05735927e-01   9.25322293e-01\n",
      "   9.62491837e-01   8.15413225e-01   9.03363325e-01   1.30360631e-02\n",
      "   5.93161524e-03   2.65179241e-02   4.75932672e-03   8.09857013e-02\n",
      "   3.34344743e-04   2.66316966e-01   6.53387932e-01   7.83473378e-01\n",
      "   8.24712005e-01]\n",
      "<bound method LikelihoodModelResults.t_test of <statsmodels.regression.linear_model.OLSResults object at 0x123ee96a0>>\n",
      "[-0.31093931  9.50547088 -4.79710413 -2.55123939  4.28860727 -0.31136374\n",
      " -0.29462705 -0.14840285  0.02661429  0.15710801 -0.08401433 -0.06147891\n",
      " -0.05047913 -0.07942393  0.11845082 -0.09375701  0.04703946 -0.23351431\n",
      "  0.12144673  2.48755225  2.75786389  2.22206362 -2.8296793   1.74688659\n",
      " -3.60048385 -1.11224978 -0.44920508 -0.27487459 -0.22155081]\n",
      "0.719521561395\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.720\n",
      "Model:                            OLS   Adj. R-squared:                  0.711\n",
      "Method:                 Least Squares   F-statistic:                     88.74\n",
      "Date:                Wed, 16 Mar 2016   Prob (F-statistic):          3.96e-236\n",
      "Time:                        19:21:22   Log-Likelihood:                -9938.8\n",
      "No. Observations:                 962   AIC:                         1.993e+04\n",
      "Df Residuals:                     934   BIC:                         2.007e+04\n",
      "Df Model:                          27                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const        -90.9803    292.598     -0.311      0.756      -665.206   483.246\n",
      "x1             2.9703      0.312      9.505      0.000         2.357     3.583\n",
      "x2            -0.7023      0.146     -4.797      0.000        -0.990    -0.415\n",
      "x3         -7.907e-05    3.1e-05     -2.551      0.011        -0.000 -1.82e-05\n",
      "x4             0.0005      0.000      4.289      0.000         0.000     0.001\n",
      "x5          -406.1252   1304.343     -0.311      0.756     -2965.908  2153.658\n",
      "x6          -390.1614   1324.255     -0.295      0.768     -2989.022  2208.699\n",
      "x7          -190.8500   1286.027     -0.148      0.882     -2714.687  2332.987\n",
      "x8            32.8558   1234.519      0.027      0.979     -2389.897  2455.608\n",
      "x9           189.0693   1203.435      0.157      0.875     -2172.681  2550.819\n",
      "x10         -104.9897   1249.665     -0.084      0.933     -2557.465  2347.486\n",
      "x11          -68.1376   1108.308     -0.061      0.951     -2243.201  2106.926\n",
      "x12          -50.9733   1009.789     -0.050      0.960     -2032.692  1930.745\n",
      "x13          -65.8616    829.241     -0.079      0.937     -1693.252  1561.529\n",
      "x14          100.3114    846.861      0.118      0.906     -1561.660  1762.283\n",
      "x15          -74.2176    791.595     -0.094      0.925     -1627.729  1479.293\n",
      "x16           40.2360    855.366      0.047      0.962     -1638.426  1718.898\n",
      "x17         -277.6157   1188.859     -0.234      0.815     -2610.761  2055.529\n",
      "x18          179.0152   1474.022      0.121      0.903     -2713.764  3071.795\n",
      "x19         3601.6668   1447.876      2.488      0.013       760.200  6443.133\n",
      "x20         3987.7994   1445.974      2.758      0.006      1150.065  6825.534\n",
      "x21         3226.3732   1451.972      2.222      0.027       376.869  6075.878\n",
      "x22        -4220.8453   1491.634     -2.830      0.005     -7148.187 -1293.503\n",
      "x23         2582.8535   1478.547      1.747      0.081      -318.805  5484.512\n",
      "x24        -5109.4947   1419.113     -3.600      0.000     -7894.515 -2324.475\n",
      "x25        -1675.4565   1506.367     -1.112      0.266     -4631.713  1280.800\n",
      "x26         -673.4208   1499.139     -0.449      0.653     -3615.492  2268.650\n",
      "x27         -403.7370   1468.804     -0.275      0.783     -3286.276  2478.802\n",
      "x28         -319.2744   1441.089     -0.222      0.825     -3147.422  2508.873\n",
      "==============================================================================\n",
      "Omnibus:                      994.481   Durbin-Watson:                   1.957\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           781410.548\n",
      "Skew:                           3.884   Prob(JB):                         0.00\n",
      "Kurtosis:                     142.407   Cond. No.                     2.79e+20\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.42e-22. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "1592.4543966\n",
      "1.57391059376\n",
      "97974.0314915\n",
      "1\n",
      "280452\n",
      "1402.04054054\n"
     ]
    }
   ],
   "source": [
    "# superbowl \n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "num_tweets_s = 0\n",
    "num_retweets_s = 0\n",
    "num_followers_s = 0\n",
    "max_followers_s = 0\n",
    "\n",
    "window_s = 1\n",
    "start_time_s = tweet_s_pdate[0]\n",
    "end_time_s = start_time_s + window_s*3600\n",
    "\n",
    "feature_s = []\n",
    "feature_s_window = []\n",
    "feature_s_window.append(1)\n",
    "\n",
    "predict_s = []\n",
    "\n",
    "for i in range(0,numtweets_s - 1):\n",
    "    \n",
    "    if tweet_s_pdate[i] < end_time_s:\n",
    "        num_tweets_s = num_tweets_s + 1\n",
    "        num_retweets_s = num_retweets_s + tweet_s_rcount[i]\n",
    "        num_followers_s = num_followers_s + tweet_s_followers[i]\n",
    "        \n",
    "        if tweet_s_followers[i] > max_followers_s:\n",
    "            max_followers_s = tweet_s_followers[i]\n",
    "    \n",
    "    else:\n",
    "        feature_s_window.append(num_tweets_s)\n",
    "        predict_s.append(num_tweets_s)\n",
    "        num_tweets_s = 1\n",
    "        \n",
    "        feature_s_window.append(num_retweets_s)\n",
    "        num_retweets_s = tweet_s_rcount[i]\n",
    "        \n",
    "        feature_s_window.append(num_followers_s)\n",
    "        num_followers_s = tweet_s_followers[i]\n",
    "        \n",
    "        feature_s_window.append(max_followers_s)\n",
    "        max_followers_s = tweet_s_followers[i]\n",
    "        \n",
    "        feature_s_window = feature_s_window + list(repeat(0,24))\n",
    "        time_index_s = int(datetime.datetime.fromtimestamp(tweet_s_pdate[i]).strftime(\"%H\"))\n",
    "        feature_s_window[6+(time_index_s-1)] = 1\n",
    "    \n",
    "        \n",
    "        \n",
    "        end_time_s = end_time_s + window_s*3600\n",
    "        \n",
    "        feature_s.append(feature_s_window)\n",
    "        feature_s_window = []\n",
    "        feature_s_window.append(1)\n",
    "        \n",
    "\n",
    "predict_s = collections.deque(predict_s)\n",
    "predict_s.rotate(-1)\n",
    "predict_s = list(predict_s) # Ground truth\n",
    "\n",
    "s_model_linear_1 = sm.OLS(predict_s,feature_s).fit()\n",
    "\n",
    "# P-value and t-value\n",
    "\n",
    "print(s_model_linear_1.pvalues)\n",
    "print(s_model_linear_1.t_test)\n",
    "print(s_model_linear_1.tvalues)\n",
    "print(s_model_linear_1.rsquared)\n",
    "print(s_model_linear_1.summary())\n",
    "\n",
    "# Using sci-kit for training accuracy\n",
    "\n",
    "s_model_linear_2 = linear_model.LinearRegression(fit_intercept=False)\n",
    "s_model_linear_2.fit(feature_s,predict_s)\n",
    "\n",
    "predicted_s = s_model_linear_2.predict(feature_s) # Predicted values\n",
    "abs_error_s = abs(predict_s - predicted_s)\n",
    "mean_abs_error_s = mean_absolute_error(predict_s,predicted_s)\n",
    "\n",
    "print(mean_abs_error_s)\n",
    "print(min(abs_error_s))\n",
    "print(max(abs_error_s))\n",
    "print(min(predict_s))\n",
    "print(max(predict_s))\n",
    "print(np.mean(predict_s))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-33e13e486a22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Hours'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Number of tweets for #superbowl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predict_s' is not defined"
     ]
    }
   ],
   "source": [
    "#superbowl Plot for question 1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(predict_s)\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Number of tweets for #superbowl')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NFL Plot for question 1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(predict_n)\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Number of tweets for #NFL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.66802521e-05   3.48326065e-03   1.70138970e-11   2.31051574e-01\n",
      "   1.75278651e-01   1.87999338e-08   4.87093135e-01   1.21250072e-04]\n",
      "<bound method LikelihoodModelResults.t_test of <statsmodels.regression.linear_model.OLSResults object at 0x11a4610b8>>\n",
      "[ 3.91526888 -2.9287853  -6.81146657  1.19841339 -1.35643729  5.67075399\n",
      "  0.69520782  3.85941409]\n",
      "0.642685295741\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.643\n",
      "Model:                            OLS   Adj. R-squared:                  0.640\n",
      "Method:                 Least Squares   F-statistic:                     246.9\n",
      "Date:                Wed, 16 Mar 2016   Prob (F-statistic):          8.89e-210\n",
      "Time:                        22:58:49   Log-Likelihood:                -7564.7\n",
      "No. Observations:                 969   AIC:                         1.515e+04\n",
      "Df Residuals:                     961   BIC:                         1.518e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const         81.8360     20.902      3.915      0.000        40.818   122.854\n",
      "x1            -4.5265      1.546     -2.929      0.003        -7.560    -1.494\n",
      "x2            -0.4193      0.062     -6.811      0.000        -0.540    -0.298\n",
      "x3          6.885e-05   5.74e-05      1.198      0.231     -4.39e-05     0.000\n",
      "x4            -0.0001   9.53e-05     -1.356      0.175        -0.000  5.78e-05\n",
      "x5             0.2670      0.047      5.671      0.000         0.175     0.359\n",
      "x6          2.367e-05   3.41e-05      0.695      0.487     -4.32e-05  9.05e-05\n",
      "x7             1.2674      0.328      3.859      0.000         0.623     1.912\n",
      "==============================================================================\n",
      "Omnibus:                     1014.757   Durbin-Watson:                   2.064\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1327656.281\n",
      "Skew:                           3.835   Prob(JB):                         0.00\n",
      "Kurtosis:                     184.175   Cond. No.                     3.36e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.36e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "143.723072626\n",
      "0.0977331838189\n",
      "10580.6733502\n"
     ]
    }
   ],
   "source": [
    "# Hawks with custom features : number of tweets, total retweet count, total citation count, max followers\n",
    "# total number of impressions count, total ranking score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "num_tweets_hawks_m = 0\n",
    "num_retweets_hawks_m = 0\n",
    "num_followers_hawks_m = 0\n",
    "max_followers_hawks_m = 0\n",
    "impressions_hawks_m = 0\n",
    "ranking_hawks_m = 0\n",
    "citations_hawks_m = 0\n",
    "\n",
    "window_hawks_m = 1\n",
    "start_time_hawks_m = tweet_hawks_pdate[0]\n",
    "end_time_hawks_m = start_time_hawks_m + window_hawks_m*3600\n",
    "\n",
    "feature_hawks_m = []\n",
    "feature_hawks_window_m = []\n",
    "feature_hawks_window_m.append(1)\n",
    "\n",
    "predict_hawks_m = []\n",
    "\n",
    "for i in range(0,numtweets_hawks - 1):\n",
    "    \n",
    "    if tweet_hawks_pdate[i] < end_time_hawks_m:\n",
    "        num_tweets_hawks_m = num_tweets_hawks_m + 1\n",
    "        num_retweets_hawks_m = num_retweets_hawks_m + tweet_hawks_rcount[i]\n",
    "        num_followers_hawks_m = num_followers_hawks_m + tweet_hawks_followers[i]\n",
    "        \n",
    "        if tweet_hawks_followers[i] > max_followers_hawks_m:\n",
    "            max_followers_hawks_m = tweet_hawks_followers[i]\n",
    "        \n",
    "        impressions_hawks_m = impressions_hawks_m + tweet_hawks_imp[i]\n",
    "        ranking_hawks_m = ranking_hawks_m + tweet_hawks_rank[i]\n",
    "        citations_hawks_m = citations_hawks_m + tweet_hawks_cite[i]\n",
    "    \n",
    "    else:\n",
    "        feature_hawks_window_m.append(num_tweets_hawks_m)\n",
    "        predict_hawks_m.append(num_tweets_hawks_m)\n",
    "        num_tweets_hawks_m = 1\n",
    "        \n",
    "        feature_hawks_window_m.append(num_retweets_hawks_m)\n",
    "        num_retweets_hawks_m = tweet_hawks_rcount[i]\n",
    "        \n",
    "        feature_hawks_window_m.append(num_followers_hawks_m)\n",
    "        num_followers_hawks_m = tweet_hawks_followers[i]\n",
    "        \n",
    "        feature_hawks_window_m.append(max_followers_hawks_m)\n",
    "        max_followers_hawks_m = tweet_hawks_followers[i]\n",
    "        \n",
    "        feature_hawks_window_m.append(citations_hawks_m)\n",
    "        citations_hawks_m = tweet_hawks_cite[i]\n",
    "        \n",
    "        feature_hawks_window_m.append(impressions_hawks_m)\n",
    "        impressions_hawks_m = tweet_hawks_imp[i]\n",
    "        \n",
    "        feature_hawks_window_m.append(ranking_hawks_m)\n",
    "        ranking_hawks_m = tweet_hawks_rank[i]\n",
    "        \n",
    "        \n",
    "        end_time_hawks_m = end_time_hawks_m + window_hawks_m*3600\n",
    "        \n",
    "        feature_hawks_m.append(feature_hawks_window_m)\n",
    "        feature_hawks_window_m = []\n",
    "        feature_hawks_window_m.append(1)\n",
    "        \n",
    "\n",
    "predict_hawks_m = collections.deque(predict_hawks_m)\n",
    "predict_hawks_m.rotate(-1)\n",
    "predict_hawks_m = list(predict_hawks_m) # Ground truth\n",
    "\n",
    "hawk_m_model_linear_1 = sm.OLS(predict_hawks_m,feature_hawks_m).fit()\n",
    "\n",
    "# P-value and t-value\n",
    "\n",
    "print(hawk_m_model_linear_1.pvalues)\n",
    "print(hawk_m_model_linear_1.t_test)\n",
    "print(hawk_m_model_linear_1.tvalues)\n",
    "print(hawk_m_model_linear_1.rsquared)\n",
    "print(hawk_m_model_linear_1.summary())\n",
    "\n",
    "# Using sci-kit for training accuracy\n",
    "\n",
    "hawk_m_model_linear_2 = linear_model.LinearRegression()\n",
    "hawk_m_model_linear_2.fit(feature_hawks_m,predict_hawks_m)\n",
    "\n",
    "predicted_hawks_m = hawk_m_model_linear_2.predict(feature_hawks_m) # Predicted values\n",
    "abs_error_hawks_m = abs(predict_hawks_m - predicted_hawks_m)\n",
    "mean_abs_error_hawks_m = mean_absolute_error(predict_hawks_m,predicted_hawks_m)\n",
    "\n",
    "print(mean_abs_error_hawks_m)\n",
    "print(min(abs_error_hawks_m))\n",
    "print(max(abs_error_hawks_m))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.76678509e-01   7.96075787e-07   5.59744947e-03   7.95030933e-13\n",
      "   2.22931655e-33   5.37565140e-12   1.74712253e-50   2.71176428e-09]\n",
      "<bound method LikelihoodModelResults.t_test of <statsmodels.regression.linear_model.OLSResults object at 0x12e54d908>>\n",
      "[  0.02924547  -4.98880951   2.78049062   7.32046318  12.80660457\n",
      "  -7.03671603 -16.44900676   6.0392029 ]\n",
      "0.744981646162\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.745\n",
      "Model:                            OLS   Adj. R-squared:                  0.742\n",
      "Method:                 Least Squares   F-statistic:                     251.2\n",
      "Date:                Wed, 16 Mar 2016   Prob (F-statistic):          5.50e-174\n",
      "Time:                        23:02:21   Log-Likelihood:                -3954.1\n",
      "No. Observations:                 610   AIC:                             7924.\n",
      "Df Residuals:                     602   BIC:                             7959.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1974      6.750      0.029      0.977       -13.059    13.454\n",
      "x1           -10.5240      2.110     -4.989      0.000       -14.667    -6.381\n",
      "x2             0.6624      0.238      2.780      0.006         0.195     1.130\n",
      "x3             0.0011      0.000      7.320      0.000         0.001     0.001\n",
      "x4             0.0020      0.000     12.807      0.000         0.002     0.002\n",
      "x5           -13.7742      1.957     -7.037      0.000       -17.618    -9.930\n",
      "x6            -0.0033      0.000    -16.449      0.000        -0.004    -0.003\n",
      "x7             2.6877      0.445      6.039      0.000         1.814     3.562\n",
      "==============================================================================\n",
      "Omnibus:                      798.522   Durbin-Watson:                   2.183\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           358268.980\n",
      "Skew:                           6.115   Prob(JB):                         0.00\n",
      "Kurtosis:                     121.094   Cond. No.                     6.89e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.89e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "34.3930623722\n",
      "0.00336751963174\n",
      "2504.3629098\n"
     ]
    }
   ],
   "source": [
    "# Go Patriots  with custom features : number of tweets, total retweet count, total citation count, max followers\n",
    "# total number of impressions count, total ranking score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "num_tweets_gp_m = 0\n",
    "num_retweets_gp_m = 0\n",
    "num_followers_gp_m = 0\n",
    "max_followers_gp_m = 0\n",
    "impressions_gp_m = 0\n",
    "ranking_gp_m = 0\n",
    "citations_gp_m = 0\n",
    "\n",
    "window_gp_m = 1\n",
    "start_time_gp_m = tweet_gp_pdate[0]\n",
    "end_time_gp_m = start_time_gp_m + window_gp_m*3600\n",
    "\n",
    "feature_gp_m = []\n",
    "feature_gp_window_m = []\n",
    "feature_gp_window_m.append(1)\n",
    "\n",
    "predict_gp_m = []\n",
    "\n",
    "for i in range(0,numtweets_gp - 1):\n",
    "    \n",
    "    if tweet_gp_pdate[i] < end_time_gp_m:\n",
    "        num_tweets_gp_m = num_tweets_gp_m + 1\n",
    "        num_retweets_gp_m = num_retweets_gp_m + tweet_gp_rcount[i]\n",
    "        num_followers_gp_m = num_followers_gp_m + tweet_gp_followers[i]\n",
    "        \n",
    "        if tweet_gp_followers[i] > max_followers_gp_m:\n",
    "            max_followers_gp_m = tweet_gp_followers[i]\n",
    "        \n",
    "        impressions_gp_m = impressions_gp_m + tweet_gp_imp[i]\n",
    "        ranking_gp_m = ranking_gp_m + tweet_gp_rank[i]\n",
    "        citations_gp_m = citations_gp_m + tweet_gp_cite[i]\n",
    "    \n",
    "    else:\n",
    "        feature_gp_window_m.append(num_tweets_gp_m)\n",
    "        predict_gp_m.append(num_tweets_gp_m)\n",
    "        num_tweets_gp_m = 1\n",
    "        \n",
    "        feature_gp_window_m.append(num_retweets_gp_m)\n",
    "        num_retweets_gp_m = tweet_gp_rcount[i]\n",
    "        \n",
    "        feature_gp_window_m.append(num_followers_gp_m)\n",
    "        num_followers_gp_m = tweet_gp_followers[i]\n",
    "        \n",
    "        feature_gp_window_m.append(max_followers_gp_m)\n",
    "        max_followers_gp_m = tweet_gp_followers[i]\n",
    "        \n",
    "        feature_gp_window_m.append(citations_gp_m)\n",
    "        citations_gp_m = tweet_gp_cite[i]\n",
    "        \n",
    "        feature_gp_window_m.append(impressions_gp_m)\n",
    "        impressions_gp_m = tweet_gp_imp[i]\n",
    "        \n",
    "        feature_gp_window_m.append(ranking_gp_m)\n",
    "        ranking_gp_m = tweet_gp_rank[i]\n",
    "        \n",
    "        \n",
    "        end_time_gp_m = end_time_gp_m + window_gp_m*3600\n",
    "        \n",
    "        feature_gp_m.append(feature_gp_window_m)\n",
    "        feature_gp_window_m = []\n",
    "        feature_gp_window_m.append(1)\n",
    "        \n",
    "\n",
    "predict_gp_m = collections.deque(predict_gp_m)\n",
    "predict_gp_m.rotate(-1)\n",
    "predict_gp_m = list(predict_gp_m) # Ground truth\n",
    "\n",
    "gp_m_model_linear_1 = sm.OLS(predict_gp_m,feature_gp_m).fit()\n",
    "\n",
    "# P-value and t-value\n",
    "\n",
    "print(gp_m_model_linear_1.pvalues)\n",
    "print(gp_m_model_linear_1.t_test)\n",
    "print(gp_m_model_linear_1.tvalues)\n",
    "print(gp_m_model_linear_1.rsquared)\n",
    "print(gp_m_model_linear_1.summary())\n",
    "\n",
    "# Using sci-kit for training accuracy\n",
    "\n",
    "gp_m_model_linear_2 = linear_model.LinearRegression()\n",
    "gp_m_model_linear_2.fit(feature_gp_m,predict_gp_m)\n",
    "\n",
    "predicted_gp_m = gp_m_model_linear_2.predict(feature_gp_m) # Predicted values\n",
    "abs_error_gp_m = abs(predict_gp_m - predicted_gp_m)\n",
    "mean_abs_error_gp_m = mean_absolute_error(predict_gp_m,predicted_gp_m)\n",
    "\n",
    "print(mean_abs_error_gp_m)\n",
    "print(min(abs_error_gp_m))\n",
    "print(max(abs_error_gp_m))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.46379958e-01   1.71613845e-03   2.53059270e-02   4.44358037e-12\n",
      "   2.87307351e-01   7.32531064e-01   9.90949955e-15   3.61714075e-02]\n",
      "<bound method LikelihoodModelResults.t_test of <statsmodels.regression.linear_model.OLSResults object at 0x123ee9320>>\n",
      "[ 0.94209182  3.14417604 -2.24016245 -7.01043296 -1.06463158  0.34185889\n",
      "  7.8634405  -2.09790604]\n",
      "0.733104670853\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.733\n",
      "Model:                            OLS   Adj. R-squared:                  0.731\n",
      "Method:                 Least Squares   F-statistic:                     381.0\n",
      "Date:                Wed, 16 Mar 2016   Prob (F-statistic):          2.24e-273\n",
      "Time:                        23:05:32   Log-Likelihood:                -8711.6\n",
      "No. Observations:                 979   AIC:                         1.744e+04\n",
      "Df Residuals:                     971   BIC:                         1.748e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const         58.1540     61.729      0.942      0.346       -62.983   179.291\n",
      "x1             4.4392      1.412      3.144      0.002         1.669     7.210\n",
      "x2            -0.2909      0.130     -2.240      0.025        -0.546    -0.036\n",
      "x3            -0.0003   4.88e-05     -7.010      0.000        -0.000    -0.000\n",
      "x4            -0.0001   9.52e-05     -1.065      0.287        -0.000  8.55e-05\n",
      "x5             0.0755      0.221      0.342      0.733        -0.358     0.509\n",
      "x6             0.0005   6.46e-05      7.863      0.000         0.000     0.001\n",
      "x7            -0.7843      0.374     -2.098      0.036        -1.518    -0.051\n",
      "==============================================================================\n",
      "Omnibus:                     1726.014   Durbin-Watson:                   1.809\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1553258.456\n",
      "Skew:                          11.686   Prob(JB):                         0.00\n",
      "Kurtosis:                     196.731   Cond. No.                     1.25e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.25e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "317.818900629\n",
      "0.734764965541\n",
      "29824.9121829\n"
     ]
    }
   ],
   "source": [
    "# Patriots with custom features : number of tweets, total retweet count, total citation count, max followers\n",
    "# total number of impressions count, total ranking score\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "num_tweets_p_m = 0\n",
    "num_retweets_p_m = 0\n",
    "num_followers_p_m = 0\n",
    "max_followers_p_m = 0\n",
    "impressions_p_m = 0\n",
    "ranking_p_m = 0\n",
    "citations_p_m = 0\n",
    "\n",
    "window_p_m = 1\n",
    "start_time_p_m = tweet_p_pdate[0]\n",
    "end_time_p_m = start_time_p_m + window_p_m*3600\n",
    "\n",
    "feature_p_m = []\n",
    "feature_p_window_m = []\n",
    "feature_p_window_m.append(1)\n",
    "\n",
    "predict_p_m = []\n",
    "\n",
    "for i in range(0,numtweets_p - 1):\n",
    "    \n",
    "    if tweet_p_pdate[i] < end_time_p_m:\n",
    "        num_tweets_p_m = num_tweets_p_m + 1\n",
    "        num_retweets_p_m = num_retweets_p_m + tweet_p_rcount[i]\n",
    "        num_followers_p_m = num_followers_p_m + tweet_p_followers[i]\n",
    "        \n",
    "        if tweet_p_followers[i] > max_followers_p_m:\n",
    "            max_followers_p_m = tweet_p_followers[i]\n",
    "        \n",
    "        impressions_p_m = impressions_p_m + tweet_p_imp[i]\n",
    "        ranking_p_m = ranking_p_m + tweet_p_rank[i]\n",
    "        citations_p_m = citations_p_m + tweet_p_cite[i]\n",
    "    \n",
    "    else:\n",
    "        feature_p_window_m.append(num_tweets_p_m)\n",
    "        predict_p_m.append(num_tweets_p_m)\n",
    "        num_tweets_p_m = 1\n",
    "        \n",
    "        feature_p_window_m.append(num_retweets_p_m)\n",
    "        num_retweets_p_m = tweet_p_rcount[i]\n",
    "        \n",
    "        feature_p_window_m.append(num_followers_p_m)\n",
    "        num_followers_p_m = tweet_p_followers[i]\n",
    "        \n",
    "        feature_p_window_m.append(max_followers_p_m)\n",
    "        max_followers_p_m = tweet_p_followers[i]\n",
    "        \n",
    "        feature_p_window_m.append(citations_p_m)\n",
    "        citations_p_m = tweet_p_cite[i]\n",
    "        \n",
    "        feature_p_window_m.append(impressions_p_m)\n",
    "        impressions_p_m = tweet_p_imp[i]\n",
    "        \n",
    "        feature_p_window_m.append(ranking_p_m)\n",
    "        ranking_p_m = tweet_p_rank[i]\n",
    "        \n",
    "        \n",
    "        end_time_p_m = end_time_p_m + window_p_m*3600\n",
    "        \n",
    "        feature_p_m.append(feature_p_window_m)\n",
    "        feature_p_window_m = []\n",
    "        feature_p_window_m.append(1)\n",
    "        \n",
    "\n",
    "predict_p_m = collections.deque(predict_p_m)\n",
    "predict_p_m.rotate(-1)\n",
    "predict_p_m = list(predict_p_m) # Ground truth\n",
    "\n",
    "p_m_model_linear_1 = sm.OLS(predict_p_m,feature_p_m).fit()\n",
    "\n",
    "# P-value and t-value\n",
    "\n",
    "print(p_m_model_linear_1.pvalues)\n",
    "print(p_m_model_linear_1.t_test)\n",
    "print(p_m_model_linear_1.tvalues)\n",
    "print(p_m_model_linear_1.rsquared)\n",
    "print(p_m_model_linear_1.summary())\n",
    "\n",
    "# Using sci-kit for training accuracy\n",
    "\n",
    "p_m_model_linear_2 = linear_model.LinearRegression()\n",
    "p_m_model_linear_2.fit(feature_p_m,predict_p_m)\n",
    "\n",
    "predicted_p_m = p_m_model_linear_2.predict(feature_p_m) # Predicted values\n",
    "abs_error_p_m = abs(predict_p_m - predicted_p_m)\n",
    "mean_abs_error_p_m = mean_absolute_error(predict_p_m,predicted_p_m)\n",
    "\n",
    "print(mean_abs_error_p_m)\n",
    "print(min(abs_error_p_m))\n",
    "print(max(abs_error_p_m))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.59312865e-04   7.52957844e-01   3.63395757e-01   2.13387479e-09\n",
      "   3.51234645e-08   2.69710498e-39   6.61163373e-01   8.55650289e-01]\n",
      "<bound method LikelihoodModelResults.t_test of <statsmodels.regression.linear_model.OLSResults object at 0x12e56d198>>\n",
      "[  3.79183439   0.31483584   0.90936579   6.04787577  -5.56126841\n",
      " -13.75819548  -0.43844985   0.1819651 ]\n",
      "0.768252153654\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.768\n",
      "Model:                            OLS   Adj. R-squared:                  0.766\n",
      "Method:                 Least Squares   F-statistic:                     434.7\n",
      "Date:                Wed, 16 Mar 2016   Prob (F-statistic):          2.48e-286\n",
      "Time:                        23:09:18   Log-Likelihood:                -6726.8\n",
      "No. Observations:                 926   AIC:                         1.347e+04\n",
      "Df Residuals:                     918   BIC:                         1.351e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const         51.3586     13.545      3.792      0.000        24.777    77.940\n",
      "x1             0.3126      0.993      0.315      0.753        -1.636     2.262\n",
      "x2             0.0457      0.050      0.909      0.363        -0.053     0.144\n",
      "x3             0.0001   1.89e-05      6.048      0.000      7.71e-05     0.000\n",
      "x4            -0.0001   2.03e-05     -5.561      0.000        -0.000  -7.3e-05\n",
      "x5            -2.0158      0.147    -13.758      0.000        -2.303    -1.728\n",
      "x6          -5.61e-06   1.28e-05     -0.438      0.661     -3.07e-05  1.95e-05\n",
      "x7             0.0401      0.221      0.182      0.856        -0.393     0.473\n",
      "==============================================================================\n",
      "Omnibus:                     1114.888   Durbin-Watson:                   2.139\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           256683.060\n",
      "Skew:                           5.715   Prob(JB):                         0.00\n",
      "Kurtosis:                      83.759   Cond. No.                     6.38e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.38e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "120.31556884\n",
      "0.0227038195281\n",
      "4440.3956869\n"
     ]
    }
   ],
   "source": [
    "# NFL with custom features : number of tweets, total retweet count, total citation count, max followers\n",
    "# total number of impressions count, total ranking score\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "num_tweets_n_m = 0\n",
    "num_retweets_n_m = 0\n",
    "num_followers_n_m = 0\n",
    "max_followers_n_m = 0\n",
    "impressions_n_m = 0\n",
    "ranking_n_m = 0\n",
    "citations_n_m = 0\n",
    "\n",
    "window_n_m = 1\n",
    "start_time_n_m = tweet_n_pdate[0]\n",
    "end_time_n_m = start_time_n_m + window_n_m*3600\n",
    "\n",
    "feature_n_m = []\n",
    "feature_n_window_m = []\n",
    "feature_n_window_m.append(1)\n",
    "\n",
    "predict_n_m = []\n",
    "\n",
    "for i in range(0,numtweets_n - 1):\n",
    "    \n",
    "    if tweet_n_pdate[i] < end_time_n_m:\n",
    "        num_tweets_n_m = num_tweets_n_m + 1\n",
    "        num_retweets_n_m = num_retweets_n_m + tweet_n_rcount[i]\n",
    "        num_followers_n_m = num_followers_n_m + tweet_n_followers[i]\n",
    "        \n",
    "        if tweet_n_followers[i] > max_followers_n_m:\n",
    "            max_followers_n_m = tweet_n_followers[i]\n",
    "        \n",
    "        impressions_n_m = impressions_n_m + tweet_n_imp[i]\n",
    "        ranking_n_m = ranking_n_m + tweet_n_rank[i]\n",
    "        citations_n_m = citations_n_m + tweet_n_cite[i]\n",
    "    \n",
    "    else:\n",
    "        feature_n_window_m.append(num_tweets_n_m)\n",
    "        predict_n_m.append(num_tweets_n_m)\n",
    "        num_tweets_n_m = 1\n",
    "        \n",
    "        feature_n_window_m.append(num_retweets_n_m)\n",
    "        num_retweets_n_m = tweet_n_rcount[i]\n",
    "        \n",
    "        feature_n_window_m.append(num_followers_n_m)\n",
    "        num_followers_n_m = tweet_n_followers[i]\n",
    "        \n",
    "        feature_n_window_m.append(max_followers_n_m)\n",
    "        max_followers_n_m = tweet_n_followers[i]\n",
    "        \n",
    "        feature_n_window_m.append(citations_n_m)\n",
    "        citations_n_m = tweet_n_cite[i]\n",
    "        \n",
    "        feature_n_window_m.append(impressions_n_m)\n",
    "        impressions_n_m = tweet_n_imp[i]\n",
    "        \n",
    "        feature_n_window_m.append(ranking_n_m)\n",
    "        ranking_n_m = tweet_n_rank[i]\n",
    "        \n",
    "        \n",
    "        end_time_n_m = end_time_n_m + window_n_m*3600\n",
    "        \n",
    "        feature_n_m.append(feature_n_window_m)\n",
    "        feature_n_window_m = []\n",
    "        feature_n_window_m.append(1)\n",
    "        \n",
    "\n",
    "predict_n_m = collections.deque(predict_n_m)\n",
    "predict_n_m.rotate(-1)\n",
    "predict_n_m = list(predict_n_m) # Ground truth\n",
    "\n",
    "n_m_model_linear_1 = sm.OLS(predict_n_m,feature_n_m).fit()\n",
    "\n",
    "# P-value and t-value\n",
    "\n",
    "print(n_m_model_linear_1.pvalues)\n",
    "print(n_m_model_linear_1.t_test)\n",
    "print(n_m_model_linear_1.tvalues)\n",
    "print(n_m_model_linear_1.rsquared)\n",
    "print(n_m_model_linear_1.summary())\n",
    "\n",
    "# Using sci-kit for training accuracy\n",
    "\n",
    "n_m_model_linear_2 = linear_model.LinearRegression()\n",
    "n_m_model_linear_2.fit(feature_n_m,predict_n_m)\n",
    "\n",
    "predicted_n_m = n_m_model_linear_2.predict(feature_n_m) # Predicted values\n",
    "abs_error_n_m = abs(predict_n_m - predicted_n_m)\n",
    "mean_abs_error_n_m = mean_absolute_error(predict_n_m,predicted_n_m)\n",
    "\n",
    "print(mean_abs_error_n_m)\n",
    "print(min(abs_error_n_m))\n",
    "print(max(abs_error_n_m))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.86262891e-01   1.13424443e-24   1.02801553e-01   3.20497228e-06\n",
      "   6.16236615e-01   1.72638249e-03   2.02400309e-03   5.54734130e-22]\n",
      "<bound method LikelihoodModelResults.t_test of <statsmodels.regression.linear_model.OLSResults object at 0x12e666438>>\n",
      "[  0.01722527  10.74716208   1.63402671   4.70365143  -0.50146437\n",
      "  -3.14849545  -3.10090018 -10.04561802]\n",
      "0.865170472287\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.865\n",
      "Model:                            OLS   Adj. R-squared:                  0.864\n",
      "Method:                 Least Squares   F-statistic:                     526.2\n",
      "Date:                Wed, 16 Mar 2016   Prob (F-statistic):          5.26e-245\n",
      "Time:                        23:12:59   Log-Likelihood:                -5605.6\n",
      "No. Observations:                 582   AIC:                         1.123e+04\n",
      "Df Residuals:                     574   BIC:                         1.126e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.9484    171.168      0.017      0.986      -333.244   339.141\n",
      "x1            16.4778      1.533     10.747      0.000        13.466    19.489\n",
      "x2             0.1608      0.098      1.634      0.103        -0.032     0.354\n",
      "x3             0.0003   5.83e-05      4.704      0.000         0.000     0.000\n",
      "x4         -2.677e-05   5.34e-05     -0.501      0.616        -0.000  7.81e-05\n",
      "x5            -0.3607      0.115     -3.148      0.002        -0.586    -0.136\n",
      "x6            -0.0002   5.64e-05     -3.101      0.002        -0.000 -6.41e-05\n",
      "x7            -3.8729      0.386    -10.046      0.000        -4.630    -3.116\n",
      "==============================================================================\n",
      "Omnibus:                     1012.673   Durbin-Watson:                   1.326\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           861844.709\n",
      "Skew:                          10.662   Prob(JB):                         0.00\n",
      "Kurtosis:                     190.311   Cond. No.                     1.35e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.35e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "643.656994176\n",
      "0.24573286015\n",
      "63360.4785281\n"
     ]
    }
   ],
   "source": [
    "# sb49 with custom features : number of tweets, total retweet count, total citation count, max followers\n",
    "# total number of impressions count, total ranking score\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "num_tweets_sb_m = 0\n",
    "num_retweets_sb_m = 0\n",
    "num_followers_sb_m = 0\n",
    "max_followers_sb_m = 0\n",
    "impressions_sb_m = 0\n",
    "ranking_sb_m = 0\n",
    "citations_sb_m = 0\n",
    "\n",
    "window_sb_m = 1\n",
    "start_time_sb_m = tweet_sb_pdate[0]\n",
    "end_time_sb_m = start_time_sb_m + window_sb_m*3600\n",
    "\n",
    "feature_sb_m = []\n",
    "feature_sb_window_m = []\n",
    "feature_sb_window_m.append(1)\n",
    "\n",
    "predict_sb_m = []\n",
    "\n",
    "for i in range(0,numtweets_sb - 1):\n",
    "    \n",
    "    if tweet_sb_pdate[i] < end_time_sb_m:\n",
    "        num_tweets_sb_m = num_tweets_sb_m + 1\n",
    "        num_retweets_sb_m = num_retweets_sb_m + tweet_sb_rcount[i]\n",
    "        num_followers_sb_m = num_followers_sb_m + tweet_sb_followers[i]\n",
    "        \n",
    "        if tweet_sb_followers[i] > max_followers_sb_m:\n",
    "            max_followers_sb_m = tweet_sb_followers[i]\n",
    "        \n",
    "        impressions_sb_m = impressions_sb_m + tweet_sb_imp[i]\n",
    "        ranking_sb_m = ranking_sb_m + tweet_sb_rank[i]\n",
    "        citations_sb_m = citations_sb_m + tweet_sb_cite[i]\n",
    "    \n",
    "    else:\n",
    "        feature_sb_window_m.append(num_tweets_sb_m)\n",
    "        predict_sb_m.append(num_tweets_sb_m)\n",
    "        num_tweets_sb_m = 1\n",
    "        \n",
    "        feature_sb_window_m.append(num_retweets_sb_m)\n",
    "        num_retweets_sb_m = tweet_sb_rcount[i]\n",
    "        \n",
    "        feature_sb_window_m.append(num_followers_sb_m)\n",
    "        num_followers_sb_m = tweet_sb_followers[i]\n",
    "        \n",
    "        feature_sb_window_m.append(max_followers_sb_m)\n",
    "        max_followers_sb_m = tweet_sb_followers[i]\n",
    "        \n",
    "        feature_sb_window_m.append(citations_sb_m)\n",
    "        citations_sb_m = tweet_sb_cite[i]\n",
    "        \n",
    "        feature_sb_window_m.append(impressions_sb_m)\n",
    "        impressions_sb_m = tweet_sb_imp[i]\n",
    "        \n",
    "        feature_sb_window_m.append(ranking_sb_m)\n",
    "        ranking_sb_m = tweet_sb_rank[i]\n",
    "        \n",
    "        \n",
    "        end_time_sb_m = end_time_sb_m + window_sb_m*3600\n",
    "        \n",
    "        feature_sb_m.append(feature_sb_window_m)\n",
    "        feature_sb_window_m = []\n",
    "        feature_sb_window_m.append(1)\n",
    "        \n",
    "\n",
    "predict_sb_m = collections.deque(predict_sb_m)\n",
    "predict_sb_m.rotate(-1)\n",
    "predict_sb_m = list(predict_sb_m) # Ground truth\n",
    "\n",
    "sb_m_model_linear_1 = sm.OLS(predict_sb_m,feature_sb_m).fit()\n",
    "\n",
    "# P-value and t-value\n",
    "\n",
    "print(sb_m_model_linear_1.pvalues)\n",
    "print(sb_m_model_linear_1.t_test)\n",
    "print(sb_m_model_linear_1.tvalues)\n",
    "print(sb_m_model_linear_1.rsquared)\n",
    "print(sb_m_model_linear_1.summary())\n",
    "\n",
    "# Using sci-kit for training accuracy\n",
    "\n",
    "sb_m_model_linear_2 = linear_model.LinearRegression()\n",
    "sb_m_model_linear_2.fit(feature_sb_m,predict_sb_m)\n",
    "\n",
    "predicted_sb_m = sb_m_model_linear_2.predict(feature_sb_m) # Predicted values\n",
    "abs_error_sb_m = abs(predict_sb_m - predicted_sb_m)\n",
    "mean_abs_error_sb_m = mean_absolute_error(predict_sb_m,predicted_sb_m)\n",
    "\n",
    "print(mean_abs_error_sb_m)\n",
    "print(min(abs_error_sb_m))\n",
    "print(max(abs_error_sb_m))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.62698847e-001   6.04472631e-077   1.21726131e-002   3.58182639e-051\n",
      "   4.41264130e-001   1.40384246e-121   1.17643697e-067   1.37445654e-080]\n",
      "<bound method LikelihoodModelResults.t_test of <statsmodels.regression.linear_model.OLSResults object at 0x12e666588>>\n",
      "[ -0.43632613  20.38270367   2.51189564  15.99081566  -0.77038188\n",
      " -27.27750889 -18.85615451 -20.96890729]\n",
      "0.89848015658\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.898\n",
      "Model:                            OLS   Adj. R-squared:                  0.898\n",
      "Method:                 Least Squares   F-statistic:                     1206.\n",
      "Date:                Wed, 16 Mar 2016   Prob (F-statistic):               0.00\n",
      "Time:                        23:15:26   Log-Likelihood:                -9450.0\n",
      "No. Observations:                 962   AIC:                         1.892e+04\n",
      "Df Residuals:                     954   BIC:                         1.895e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const        -70.4339    161.425     -0.436      0.663      -387.223   246.355\n",
      "x1            43.8996      2.154     20.383      0.000        39.673    48.126\n",
      "x2             0.2653      0.106      2.512      0.012         0.058     0.473\n",
      "x3             0.0004   2.74e-05     15.991      0.000         0.000     0.000\n",
      "x4         -5.763e-05   7.48e-05     -0.770      0.441        -0.000  8.92e-05\n",
      "x5            -4.4411      0.163    -27.278      0.000        -4.761    -4.122\n",
      "x6            -0.0003   1.75e-05    -18.856      0.000        -0.000    -0.000\n",
      "x7            -9.7090      0.463    -20.969      0.000       -10.618    -8.800\n",
      "==============================================================================\n",
      "Omnibus:                      949.297   Durbin-Watson:                   1.981\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           362431.975\n",
      "Skew:                           3.772   Prob(JB):                         0.00\n",
      "Kurtosis:                      97.789   Cond. No.                     1.56e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.56e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "1062.85772416\n",
      "0.262122529033\n",
      "64173.4539195\n"
     ]
    }
   ],
   "source": [
    "# superbowl  with custom features : number of tweets, total retweet count, total citation count, max followers\n",
    "# total number of impressions count, total ranking score\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "num_tweets_s_m = 0\n",
    "num_retweets_s_m = 0\n",
    "num_followers_s_m = 0\n",
    "max_followers_s_m = 0\n",
    "impressions_s_m = 0\n",
    "ranking_s_m = 0\n",
    "citations_s_m = 0\n",
    "\n",
    "window_s_m = 1\n",
    "start_time_s_m = tweet_s_pdate[0]\n",
    "end_time_s_m = start_time_s_m + window_s_m*3600\n",
    "\n",
    "feature_s_m = []\n",
    "feature_s_window_m = []\n",
    "feature_s_window_m.append(1)\n",
    "\n",
    "predict_s_m = []\n",
    "\n",
    "for i in range(0,numtweets_s - 1):\n",
    "    \n",
    "    if tweet_s_pdate[i] < end_time_s_m:\n",
    "        num_tweets_s_m = num_tweets_s_m + 1\n",
    "        num_retweets_s_m = num_retweets_s_m + tweet_s_rcount[i]\n",
    "        num_followers_s_m = num_followers_s_m + tweet_s_followers[i]\n",
    "        \n",
    "        if tweet_s_followers[i] > max_followers_s_m:\n",
    "            max_followers_s_m = tweet_s_followers[i]\n",
    "        \n",
    "        impressions_s_m = impressions_s_m + tweet_s_imp[i]\n",
    "        ranking_s_m = ranking_s_m + tweet_s_rank[i]\n",
    "        citations_s_m = citations_s_m + tweet_s_cite[i]\n",
    "    \n",
    "    else:\n",
    "        feature_s_window_m.append(num_tweets_s_m)\n",
    "        predict_s_m.append(num_tweets_s_m)\n",
    "        num_tweets_s_m = 1\n",
    "        \n",
    "        feature_s_window_m.append(num_retweets_s_m)\n",
    "        num_retweets_s_m = tweet_s_rcount[i]\n",
    "        \n",
    "        feature_s_window_m.append(num_followers_s_m)\n",
    "        num_followers_s_m = tweet_s_followers[i]\n",
    "        \n",
    "        feature_s_window_m.append(max_followers_s_m)\n",
    "        max_followers_s_m = tweet_s_followers[i]\n",
    "        \n",
    "        feature_s_window_m.append(citations_s_m)\n",
    "        citations_s_m = tweet_s_cite[i]\n",
    "        \n",
    "        feature_s_window_m.append(impressions_s_m)\n",
    "        impressions_s_m = tweet_s_imp[i]\n",
    "        \n",
    "        feature_s_window_m.append(ranking_s_m)\n",
    "        ranking_s_m = tweet_s_rank[i]\n",
    "        \n",
    "        \n",
    "        end_time_s_m = end_time_s_m + window_s_m*3600\n",
    "        \n",
    "        feature_s_m.append(feature_s_window_m)\n",
    "        feature_s_window_m = []\n",
    "        feature_s_window_m.append(1)\n",
    "        \n",
    "\n",
    "predict_s_m = collections.deque(predict_s_m)\n",
    "predict_s_m.rotate(-1)\n",
    "predict_s_m = list(predict_s_m) # Ground truth\n",
    "\n",
    "s_m_model_linear_1 = sm.OLS(predict_s_m,feature_s_m).fit()\n",
    "\n",
    "# P-value and t-value\n",
    "\n",
    "print(s_m_model_linear_1.pvalues)\n",
    "print(s_m_model_linear_1.t_test)\n",
    "print(s_m_model_linear_1.tvalues)\n",
    "print(s_m_model_linear_1.rsquared)\n",
    "print(s_m_model_linear_1.summary())\n",
    "\n",
    "# Using sci-kit for training accuracy\n",
    "\n",
    "s_m_model_linear_2 = linear_model.LinearRegression()\n",
    "s_m_model_linear_2.fit(feature_s_m,predict_s_m)\n",
    "\n",
    "predicted_s_m = s_m_model_linear_2.predict(feature_s_m) # Predicted values\n",
    "abs_error_s_m = abs(predict_s_m - predicted_s_m)\n",
    "mean_abs_error_s_m = mean_absolute_error(predict_s_m,predicted_s_m)\n",
    "\n",
    "print(mean_abs_error_s_m)\n",
    "print(min(abs_error_s_m))\n",
    "print(max(abs_error_s_m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7.18407078e-01   5.53695153e-19   2.75911023e-10   2.22397467e-04]\n",
      "0.705273498858\n"
     ]
    }
   ],
   "source": [
    "# superbowl Q2 significance testing \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "num_tweets_s = 0\n",
    "num_retweets_s = 0\n",
    "#num_followers_s = 0\n",
    "max_followers_s = 0\n",
    "\n",
    "window_s = 1\n",
    "start_time_s = tweet_s_pdate[0]\n",
    "end_time_s = start_time_s + window_s*3600\n",
    "\n",
    "feature_s = []\n",
    "feature_s_window = []\n",
    "feature_s_window.append(1)\n",
    "\n",
    "predict_s = []\n",
    "\n",
    "for i in range(0,numtweets_s - 1):\n",
    "    \n",
    "    if tweet_s_pdate[i] < end_time_s:\n",
    "        num_tweets_s = num_tweets_s + 1\n",
    "        num_retweets_s = num_retweets_s + tweet_s_rcount[i]\n",
    "        #num_followers_s = num_followers_s + tweet_s_followers[i]\n",
    "        \n",
    "        if tweet_s_followers[i] > max_followers_s:\n",
    "            max_followers_s = tweet_s_followers[i]\n",
    "    \n",
    "    else:\n",
    "        feature_s_window.append(num_tweets_s)\n",
    "        predict_s.append(num_tweets_s)\n",
    "        num_tweets_s = 1\n",
    "        \n",
    "        feature_s_window.append(num_retweets_s)\n",
    "        num_retweets_s = tweet_s_rcount[i]\n",
    "        \n",
    "        #feature_s_window.append(num_followers_s)\n",
    "        #num_followers_s = tweet_s_followers[i]\n",
    "        \n",
    "        feature_s_window.append(max_followers_s)\n",
    "        max_followers_s = tweet_s_followers[i]\n",
    "        \n",
    "        #feature_s_window = feature_s_window + list(repeat(0,24))\n",
    "        #time_index_s = int(datetime.datetime.fromtimestamp(tweet_s_pdate[i]).strftime(\"%H\"))\n",
    "        #feature_s_window[6+(time_index_s-1)] = 1\n",
    "    \n",
    "        \n",
    "        \n",
    "        end_time_s = end_time_s + window_s*3600\n",
    "        \n",
    "        feature_s.append(feature_s_window)\n",
    "        feature_s_window = []\n",
    "        feature_s_window.append(1)\n",
    "        \n",
    "\n",
    "predict_s = collections.deque(predict_s)\n",
    "predict_s.rotate(-1)\n",
    "predict_s = list(predict_s) # Ground truth\n",
    "\n",
    "s_model_linear_1 = sm.OLS(predict_s,feature_s).fit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(s_model_linear_1.pvalues)\n",
    "print(s_model_linear_1.rsquared)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7.23495884e-002   2.25607434e-034   3.89470680e-145   1.45486669e-031]\n",
      "0.849011047545\n"
     ]
    }
   ],
   "source": [
    "# sb49 Q3 significance testing \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "num_tweets_s_m = 0\n",
    "#num_retweets_s_m = 0\n",
    "#num_followers_s_m = 0\n",
    "#max_followers_s_m = 0\n",
    "#impressions_s_m = 0\n",
    "ranking_s_m = 0\n",
    "citations_s_m = 0\n",
    "\n",
    "window_s_m = 1\n",
    "start_time_s_m = tweet_s_pdate[0]\n",
    "end_time_s_m = start_time_s_m + window_s_m*3600\n",
    "\n",
    "feature_s_m = []\n",
    "feature_s_window_m = []\n",
    "feature_s_window_m.append(1)\n",
    "\n",
    "predict_s_m = []\n",
    "\n",
    "for i in range(0,numtweets_s - 1):\n",
    "    \n",
    "    if tweet_s_pdate[i] < end_time_s_m:\n",
    "        num_tweets_s_m = num_tweets_s_m + 1\n",
    "        #num_retweets_s_m = num_retweets_s_m + tweet_s_rcount[i]\n",
    "        #num_followers_s_m = num_followers_s_m + tweet_s_followers[i]\n",
    "        \n",
    "        #if tweet_s_followers[i] > max_followers_s_m:\n",
    "            #max_followers_s_m = tweet_s_followers[i]\n",
    "        \n",
    "        #impressions_s_m = impressions_s_m + tweet_s_imp[i]\n",
    "        ranking_s_m = ranking_s_m + tweet_s_rank[i]\n",
    "        citations_s_m = citations_s_m + tweet_s_cite[i]\n",
    "    \n",
    "    else:\n",
    "        feature_s_window_m.append(num_tweets_s_m)\n",
    "        predict_s_m.append(num_tweets_s_m)\n",
    "        num_tweets_s_m = 1\n",
    "        \n",
    "        #feature_s_window_m.append(num_retweets_s_m)\n",
    "        #num_retweets_s_m = tweet_s_rcount[i]\n",
    "        \n",
    "        #feature_s_window_m.append(num_followers_s_m)\n",
    "        #num_followers_s_m = tweet_s_followers[i]\n",
    "        \n",
    "        #feature_s_window_m.append(max_followers_s_m)\n",
    "        #max_followers_s_m = tweet_s_followers[i]\n",
    "        \n",
    "        feature_s_window_m.append(citations_s_m)\n",
    "        citations_s_m = tweet_s_cite[i]\n",
    "        \n",
    "        #feature_s_window_m.append(impressions_s_m)\n",
    "        #impressions_s_m = tweet_s_imp[i]\n",
    "        \n",
    "        feature_s_window_m.append(ranking_s_m)\n",
    "        ranking_s_m = tweet_s_rank[i]\n",
    "        \n",
    "        \n",
    "        end_time_s_m = end_time_s_m + window_s_m*3600\n",
    "        \n",
    "        feature_s_m.append(feature_s_window_m)\n",
    "        feature_s_window_m = []\n",
    "        feature_s_window_m.append(1)\n",
    "        \n",
    "\n",
    "predict_s_m = collections.deque(predict_s_m)\n",
    "predict_s_m.rotate(-1)\n",
    "predict_s_m = list(predict_s_m) # Ground truth\n",
    "\n",
    "s_m_model_linear_1 = sm.OLS(predict_s_m,feature_s_m).fit()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(s_m_model_linear_1.pvalues)\n",
    "print(s_m_model_linear_1.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
